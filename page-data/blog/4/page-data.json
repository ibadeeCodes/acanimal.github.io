{"componentChunkName":"component---src-templates-blog-list-js","path":"/blog/4","webpackCompilationHash":"94830e9bd36aba932e6a","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"9fd50913-90e6-5b23-8d72-375e323f81d3","frontmatter":{"title":"I'm working on ClydeIO","date":"14 September, 2015","layout":"post"},"fields":{"slug":"/blog/2015/09/14/i-m-working-on-clydeio/","readingTime":{"text":"5 min read"}},"excerpt":"ClydeIO is an open source API gateway and management layer based on nodejs. It is extremely flexibly, configurable and simply to extend. It is designed to simplify the development of new APIs (or simply improving existing ones) adding authentication, logging, rate limiting, etc. Note, the project is currently a proof of concept (I'm currently working to apply it in a real system) and most of the developed filters are basic implementation to demonstrate its usefulness. What is an API gateway and why I need one? The most important part when designing and implementing an API is to model your business correctly and offer a set of well defined operations accordingly with them. Unfortunately, that is only an small part of the job and it is not enough to ensure the success. As a real World system you require to secure your API, store logs, apply rate limits, etc. The task of publishing an API becomes much more complex than understanding your business, you have entered the world of security, monitoring and... the unknown !!! An API gateway is a single point of entry responsible to apply actions (like security or logging) before redirecting the request to your real-do-the-job API. We can see the gateway as a kind (or mix) of firewall and proxy and is really useful implementing microservices.  Thanks to ClydeIO you can spend your efforts implementing your business API leaving the rest of things to the gateway. The glory of ClydeIO is its simplicity and its easy to extent with new filters like: Secure an existent API Log access to any resource Rate limiting Filter request (allow/deny) depending on the query parameters Cache data or whatever you need  Because it is based on node we can use the myriad of awesome node packages out there and integrate within your filters.  Why a new system instead contribute to an existent one? I was looking for similar projects before start ClydeIO. There is plenty of services that provides same functionalities (and many more) as well as many projects with a great maturity level, but no one satisfies my needs. Services implies a cost for its usage that, sometimes, can be hard to calculate and in some cases requires you adapt your systems (your business API) to accommodate to the service requirements. Other software projects means you must be comfortable with the technology they are implemented with, mainly its programming language and database used to store configuration and information. One thing I saw in common in most of the software projects is the fact they do what they do, that is, they are prepared to make many things, do it well but are not allowed to extend the gateway easily with new requirements users can have. They are designed to make the most common things: rate limiting, security, logging, etc but it is hard to know how we can extend the gateway to send us an email when there was more than ten invalid accesses. In addition, I found some of them really complex to configure, based on monster XML configuration files. Once last comment on why I created ClydeIO: to take advantage of the node modules. There exists other API gateways implemented using NGINX server, lua, go or python language but nonetheless implemented with node. To be honest I must point here the StrongLoop LoopBack API Gateway product. Current status ClydeIO is currently a proof of concept and I have implemented a bunch of filters to test its capabilities. Currently all configuration is provided via a JSON file. That's nice and simply but not much secure when working with authentication filters that needs specify users and passwords or with a real scenario that requires manage hundred of users. Because of this I'm currently working hard trying to create the configuration module, responsible to manage the whole configuration, and designing to be easy to implement for different backends: memory, redis, mongodb, postgresql, ... I have great feeling about ClydeIO's possibilities but to be honest it is currently a personal side project I write on my few free time. I have no contributors neither sponsors. So, if you arrive to this page and are interested in the project feel free to contact with me and start helping with your money or time :) Documentation I have create the ClydeIO github organization to host all the related projects related with ClydeIO. We can differentiate among the core project, so called clydeio too and the rest of projects that are clyde's filters. The current core project documentation can be found at the project's wiki: https://github.com/clydeio/clydeio/wiki. It will probably change soon, once finished the configuration module, but the concepts remains the same. Contributions As a said, for the moment this is a personal project I develop on my free time. So don't hesitate to contact with me for any kind of support and help."}},{"node":{"id":"eb5405e2-96c8-51a3-a28f-048bf1b2a557","frontmatter":{"title":"How to read from a writable stream (http.ServerResponse) in Node","date":"31 August, 2015","layout":"post"},"fields":{"slug":"/blog/2015/08/31/how-to-read-from-a-writable-stream-httpserverresponse-in-node/","readingTime":{"text":"3 min read"}},"excerpt":"I'm working on a personal side project (when I have free time to spend on) where a bunch of middlewares are chained to do something awesome (Take a look at ClydeIO. Note it is currently a proof of concept). Remember a middleware is nothing more than a function that receives three parameters: the , the  and the  function: The  parameter is an instance of , a readable stream, while the  parameter is an instance of , a writable stream (something similar to Java servlets). Usually a middleware reads the request, optionally attach more data or modifies it, maybe writes some content on the response and continues the execution in the next middleware invoking the  function. If any of the middlewares writes content and invokes the  method the response is sent to the client and middleware chain is aborted. Note, I'm working with Connect and not Express, but the concepts are the same.\nExpress uses the  method to write content, which is based in the  and  core node methods. Also Express extends with request and response object with its own methods. Now, suppose in a middleware you need to get the current content (the response body) other middlewares has been written. The response is an output stream and it is designed to have write oriented operations: write content, write headers, etc but not read operations. So how we can read the content written on a writable stream? Do not confuse the response reference we have in a middleware (or simply in a  listener), which is a writable stream, with the object we obtain when using . With  we obtain an instance of  and when listen on it for the  event we get a , a readable stream. That is, the response we obtain is a readable stream where we can read data sent from the server. In a middleware we are the server and are responsible to write data in an output/writable stream. The solution I found is override the  method. The  method is defined by the  interface and it is mandatory each writable stream class implements it. So, they idea is to override the method in a way we can store the data is written and later invoking the parent method so they what usually do: Now, the second middleware can read all the chunks of data any other middleware writes to the response and continues the normal execution of the  function invoking the original version. Note, if you need to access the response headers the solution is similar but, in this case, you need to override the methods ,  and ."}},{"node":{"id":"b066c5d9-1787-5630-ba9c-e5456666493d","frontmatter":{"title":"Using random unsplash images on your website","date":"17 August, 2015","layout":"post"},"fields":{"slug":"/blog/2015/08/18/using-random-unsplash-images/","readingTime":{"text":"2 min read"}},"excerpt":"Recently I updated my we page and one of the nice features I included on it is the fact a random image is placed in the header for each page. These images are obtained from the great unsplash, a free (do whatever you want) high-resolution photos project. As its slogan says, unsplash contains tons of really good images, both by its resolution and the photographies. To embed the unsplash images in my web site I used the unsplash.it service, its slogan says Beautiful placeholders using images from unsplash.  It was created by  David Marby and Nijiko Yonskai and the code is publicly available at the github unsplash-it repository (if you are interested it is a NodeJS based project). But what does exactly unsplash.it? Basically it returns images from unsplash project with some steroids. Retrieve an image indicating the desired width and height: https://unsplash.it/500/400 Using a square image: https://unsplash.it/500 Get a random image: https://unsplash.it/500/400?random or maybe grey styled: https://unsplash.it/g/500/400?random Obtain a list of available images: https://unsplash.it/list And retrieve a given image: https://unsplash.it/500?image=123 Maybe a bit blured: https://unsplash.it/500?image=123&blur And finally, cropping if desired: https://unsplash.it/500?image=123&gravity=east Yeah !!! unsplash.it is nice service easy and free to use."}},{"node":{"id":"ff5368ee-8533-5694-8d71-f714e35b8881","frontmatter":{"title":"Migrating from WordPress to Jekyll","date":"11 August, 2015","layout":"post"},"fields":{"slug":"/blog/2015/08/06/migrating-from-wordpress-to-jekyll/","readingTime":{"text":"3 min read"}},"excerpt":"WordPress is awesome, an incredible project with thousands of plugins that does not need any presentation. What start as a blogging platform has become a powerful framework to build almost anything. All that is fine, but... recently I migrated this blog from WordPress to Jekyll. The problem for me is WordPress starts as a quick solution to have a blog but has increasingly become a two big resource to administer. I have installed plugins to manage spam, to limit access login (for security reasons), to share content on social networks, to highlight source code, to add Google Analytics code, etc. I have a tech blog. I write about programming, libraries and how to do things, accompanied by sample code. WordPress WYSIWYG editor is great but not agile to write code. On the other side the test view of the content is poor and becomes affected by the visual view each time you change between tabs. Jekyll is much simpler than WordPress. It is much more less powerful than WordPress in many aspects but if offers me what I need in a more simpler way. Jekyll is an static site generator. Opposite to WordPress, written in PHP, where each request implies a query to get data, apply some process and finally return the resultant page, Jekyll has a completely different philosophy. With Jekyll you write content in markdown syntax and applying some rules, mainly a front matter section on pages and posts. Once you agree with your content Jekyll compiles them and builds an static version of all your content ready to be hosted. For those with a GitHub account, remember if you put all the content on a repository there is no need to compile because GitHub does it for you each time you push commit. Yes, you write directly in markdown syntax on any text editor, there is no visual editor like in WordPress, but it is exactly what I need: to have as much control as I can over what I write. In fact, the writing process results quickest than using the WYSIWYG mode in WordPress, especially when I require to write code. The migration process To be honest I must admit in my case it was a bit traumatic, in part because I'm a bit tiquismiquis with my things. The steps about the migration were basically: Export your WordPress content on Tools > Export menu.  Use jekyll-import tool to create a jekyll site from the WordPress export file. The tool creates all the posts and pages but unfortunally attach to much information on the front-matter section I don't like neither want. So I must apply many modification manually on each postand, in most cases to translate from HTML to markdown syntax (using the only to-markdown translator tool). Migrate all WordPress comments to Disqus platform. For this, I need to install the Disqus Comment System plugin and have a configured account. Once you configure the plugin all the comments are migrated automatically. Here the step was a bit more cumbersome because the new blog is in a different URL. So I need to export all the Disqus discussions, update manually all the URLs and import again in the system.  Chose a jekyll theme and adapt a bit for my needs. I chose the Kasper, a Ghost's theme ported to jekyll. I changed the theme to include some more header buttons (one for each page) and add random images, from the unsplash project using the nice unsplash.it service. The result is I have a blog I feel really comfortable :)"}},{"node":{"id":"edb915db-95f8-559d-b8b2-85f8730b807e","frontmatter":{"title":"Working with different environments on jekyll","date":"04 August, 2015","layout":"post"},"fields":{"slug":"/blog/2015/08/04/working-with-different-environments-on-jekyll/","readingTime":{"text":"3 min read"}},"excerpt":"Jekyll is an open source static site generator. It allows writing content in markdown (also HTML) using some rules, like adding some front matter on pages or posts. Later jekyll compiles all the code and generates an static version for each page and post. The benefits of having an static site are mainly speed. Contrary to other blog engines like WordPress, where each request requires server works querying data, processing and returning the page, jekyll only does that work once, when the static site is built. Jekyll is also well known by the fact it is used by GitHub. If you host your jekyll posts on a GitHub repository you don't require to compile them because GitHub does for you each time you make a commit. If you are interested on this topic see pages and take a look at pages basics. A few days ago I migrate this blog from WordPress to Jekyll. Note its source code, with all the post I wrote and will write al publicly available at https://github.com/acanimal/acuriousanimal-blog.github.io. The method I follow to write is: I write in my local version of jekyll. Once I finish an article... I run jekyll locally to see all looks fine. If all is fine... I commit the changes to the GitHub repository. This makes GitHub compiles the posts and generates the same content like me. Something I missed from the beginning was the possibility to have a different configuration depending if on the environment. When working locally I want all links and images point to my local computer, while when I upload content to GitHub I want links to be relative to GitHub hosting. Hopefully this is really easy to achieve using more than one configuration file. I have a main  where all variables are set. Next is part of my current configuration file: In addition, I have a  file I only use when working locally. This files contains all variables I want to redefine when working locally. For example: Jekyll commands allow to specify more than one configuration file. We simply must remember a variable existent in a configuration file can be overridden with a value on the second file. Having this in mind, I run jekyll locally with the next command: This produces the value of  specified at  becomes overridden by the value of  variable specified at ."}},{"node":{"id":"0c371987-6ed1-51a8-9c67-5423e3096996","frontmatter":{"title":"Generate and host your own raster tiles customized with Mapbox Studio","date":"26 July, 2015","layout":"post"},"fields":{"slug":"/blog/2015/07/26/generate-and-host-your-own-raster-tiles-customized-with-mapbox-studio/","readingTime":{"text":"9 min read"}},"excerpt":"If you have never saw maps hosted in Mapbox platform you would probably agree on the quality of its designs. The business of Mapbox is to host and server geospatial data. For this reason, all the great tools Mapbox facilitates are oriented to help their users to prepare and work with their data. One of the provided tools is Mapbox Studio. Mapbox Studio (MbS) is a desktop application that allows to create CartoCSS themes that are later used to generate raster tiles. Briefly explained, what MbS does is to download OpenStreetMap data in vector format and render it on the fly applying the specified CartoCSS style. The result of working with MbS is not a set of tiles but a style, that is, a set of rules that express which colour must be used to render roads, at which levels must labels appears and with which size, which colour must be used for ground, etc. This style can be later uploaded to Mapbox platform so that raster tiles were generated on the cloud and we can consume the tiles paying for the service. (Hope one day I can contract their services, they deserve by their great job). The question we can make us is: how we can generate the raster tiles locally from a given MbS style? Well, this article is about that. Continue reading. Working with Mapbox Studio and create your custom style Let's start from the beginning so download Mapbox Studio application and install on your system. Once installed execute it and you will be asked to be connected to the Mapbox platform. There are two main reasons why Mapbox requires you to register as a user. First, the power of the platform is on the cloud and the goal is you upload all your data to the servers. That includes the styles you create. Second, MbS retrieves data in vector format from Mapbox servers. When you register as a user you get an API token that identifies your requests. Each time MbS makes a request to extract data it has your token that identifies you as user. This way Mapbox can control if any user is making a bad usage of their platform.  Once logged in you will be allowed to create new map styles. The easiest way is to start using one of the starter styles created by the great Mapbox designers:  Here we have chose the Mapbox Outdoors style. In the image you can see the style code (CartoCSS which is inspered by CSS) and the resultant tiles obtaining from painting the vector information with the given style rules: CartoCSS is a Mapnik stylesheet pre-processor developed by MapBox and inspired by Cascadenik. It is like a CSS language specially developed to style maps.  Store the style with a new name somewhere on your computer, for example, . If you look at your disk you will see a  folder has been created containing a bunch of files that defines the style rules (take a look they are not dangerous). Finally, modify some properties, for example  or  colors and save to see the result:  Great !!! You just have created your first custom style. Generating raster tiles from MbS style Looking for a solution I discovered the tessera and tl tools. Tessera is a node based command line application. It is based in some modules from mapbox (concretely tilelive) plus others implemented by the author (Seth Fitzsimmons). The result is we can execute tessera passing a MbS defined style, open a browser pointing to a local address and see a map with the raster tiles generated with our MbS style. Similarly, tl is a node based command line tool we can execute, passing a set of options, to generate a MBTiles file or a pyramid of tiles following the well known  format. I know about both tools at the article Converting Mapbox Studio Vector Tiles to Rasters from Azavea Labs. How to install the tools? NOTE: You need to have NodeJS installed in your system, along with the npm package manager command line tools. I don't like to install global node packages (or at least more than the necessary) so I'm going to install the previous tools in a custom folder: {% highlight bash %} mkdir tiletools\ncd tiletools\n{% endhighlight %} Inside the directory execute next sentence, which install the  and  packages among others: {% highlight bash %} npm install tessera tl mbtiles mapnik tilelive tilelive-file tilelive-http tilelive-mapbox tilelive-mapnik tilelive-s3 tilelive-tmsource tilelive-tmstyle tilelive-utfgrid tilelive-vector tilejson\n{% endhighlight %} You will see a hidden directory named  has been created which contains some subdirectories with the same name as the previous packages. Running tessera Let's try to run tessera for the first time. Because it is installed as a local node module execute: {% highlight bash %} ./node_modules/tessera/bin/tessera.js Usage: node tessera.js uri options uri     tilelive URI to serve Options:\n   -C SIZE, --cache-size SIZE          Set the cache size (in MB)  10\n   -c CONFIG, --config CONFIG          Provide a configuration file\n   -p PORT, --port PORT                Set the HTTP Port  8080\n   -r MODULE, --require MODULE         Require a specific tilelive module\n   -S SIZE, --source-cache-size SIZE   Set the source cache size (in # of sources)  10\n   -v, --version                       Show version info A tilelive URI or configuration file is required.\n{% endhighlight %} Tessera requires you pass an URI so it can server its content. It accepts URIs from Mapbox hosted file, Mapnik, Tilemill, Mapbox Studio, ... Repeat again indicating the path to our previously created style indicating the protocol . {% highlight bash %} ./node_modules/tessera/bin/tessera.js tmstyle://./customstyle.tm2\nListening at http://0.0.0.0:8080/ /Users/antonio/Downloads/tiletools/nodemodules/tessera/server.js:43\n        throw err;\n              ^\nError: A Mapbox access accessToken is required. `export MAPBOXACCESS_TOKEN=...` to set.\n...\n{% endhighlight %} First seems tessera is working at port 8080 but later we get an error about . If you remember from the first section, Mapbox requires all the requests be signed with the user token. So, you need to get the access token from your account and set it as environment variable before execute tessera: {% highlight bash %} export MAPBOXACCESSTOKEN=yourtokenhere\n./node_modules/tessera/bin/tessera.js tmstyle://./customstyle.tm2\nListening at http://0.0.0.0:8080/ /Users/antonio/Downloads/tiletools/node_modules/tessera/server.js:43\n        throw err;\n              ^\nError: Failed to find font face 'Open Sans Bold' in FontSet 'fontset-0' in FontSet\n{% endhighlight %} We are close to make it work. The problem now is our MbS style is using a font we have not installed in our system. One easy, but brute force, solution is to install all Google Web Fonts on your system. For this purpose you can use the Web Font Load installation script. In my case I have installed them in the user's fonts folder . Once fonts were installed try executing tessera again: {% highlight bash %} ./node_modules/tessera/bin/tessera.js tmstyle://./customstyle.tm2\nListening at http://0.0.0.0:8080/ /Users/antonio/Downloads/tiletools/node_modules/tessera/server.js:43\n        throw err;\n              ^\nError: Failed to find font face 'Open Sans Bold' in FontSet 'fontset-0' in FontSet\n{% endhighlight %} That' s a bit strange, we have just installed the fonts but they are not found. What is happening? Well, tessera uses mapnik to create the raster tiles and it looks for fonts in the folders specified by the environment variable , so let define the variable: {% highlight bash %} export MAPNIKFONTPATH=~/Library/Fonts/\n{% endhighlight %} and execute the script again: {% highlight bash %} ./node_modules/tessera/bin/tessera.js tmstyle://./customstyle.tm2\nListening at http://0.0.0.0:8080/ /Users/antonio/Downloads/tiletools/node_modules/tessera/server.js:43\n        throw err;\n              ^\nError: Failed to find font face 'Arial Unicode MS Regular' in FontSet 'fontset-0' in FontSet\n{% endhighlight %} OMG !!! This seems a never ending story. Now we need to install the Arial Unicode font. Look for it, install in your system and execute tessera again: {% highlight bash %} ./node_modules/tessera/bin/tessera.js tmstyle://./customstyle.tm2\nListening at http://0.0.0.0:8080/\n{% endhighlight %} Great !!! It seems tessera is working fine. Let's go to open our browser pointing to  and see the result:  A map implemented using Leaflet web mapping library is shown, rendering raster tiles that are created in the fly. Look at the console to see the tessera output information:  We can see how tiles at current zoom, the zoom level 8, has been generated. At this point we have tessera working but what about generate a local pyramid of tiles for a given zoom levels and a given bounding box? Generating a custom pyramid of tiles with tl command line tool Before continue we need to know which bounding box we want to generate, the whole World? or only a piece. In my case I want three zoom levels (7, 8 and 9) wrapping Catalonia. There are some online tools you can use to get the bbox of a region, but one I like it the Bounding Box Tool from Klokan Technologies. The tl tool can run three main commands but are only interested in the copy one, which copies data between two providers. In our case the MbS style is one provider and the file system is the other. Run the tl command to see the available options: {% highlight bash %} ./node_modules/tl/bin/tl.js copy --help Usage: node tl.js copy   options source     source URI\nsink       sink URI Options:\n   -v, --version                 Show version info\n   -b BBOX, --bounds BBOX        WGS84 bounding box  -180,-85.0511,180,85.0511\n   -z ZOOM, --min-zoom ZOOM      Min zoom (inclusive)  0\n   -Z ZOOM, --max-zoom ZOOM      Max zoom (inclusive)  22\n   -r MODULE, --require MODULE   Require a specific tilelive module\n   -s SCHEME, --scheme SCHEME    Copy scheme  scanline\n   -i FILE, --info FILE          TileJSON copy data between tilelive providers\n{% endhighlight %} So let's go to execute the command to copy data from our MbS style to the local  folder. We want to generate tiles from zoom level 7 to 9 and indicating a bounding box wrapping Catalonia. Remember the  options must be indicated as . {% highlight bash %} ./node_modules/tl/bin/tl.js copy -z 7 -Z 9 -b \"0.023293972 40.4104003077 3.6146087646 42.9542303723\" tmstyle://./customstyle.tm2/ file://./tiles\nSegmentation fault: 11\n{% endhighlight %} Ough !!! That hurts, a segmentation fault. After looking for a while I realised it seems a bug. To solve it go to  and remove the  folder dependency. It is redundant because there is one installed in parent folder. Execute the command again and see the output:  The tl tool has created a local tiles directory and generated all the raster tiles for the given zoom levels and bounding box. The output shows in addition the time required to generate each tile. That's all. Now we only need to host the tiles at our own servers !!!"}}]}},"pageContext":{"isCreatedByStatefulCreatePages":false,"limit":6,"skip":18,"numPages":18,"currentPage":4}}}