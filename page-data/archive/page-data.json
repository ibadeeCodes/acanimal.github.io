{"componentChunkName":"component---src-pages-archive-js","path":"/archive/","webpackCompilationHash":"dfd26dbe3cbb7e082b48","result":{"data":{"allMarkdownRemark":{"totalCount":105,"edges":[{"node":{"id":"3c3aa555-904a-585d-ba97-14f3a51f0268","frontmatter":{"title":"How to update a column's type (in PostgreSQL)","date":"2020-01-04 16:01"},"fields":{"slug":"/blog/2020/01/04/updating-column-type","readingTime":{"text":"2 min read"}},"excerpt":"So, you have a table and you need to modify a column's type. The problem arise when the column is filled and the type change is incompatible, for example, from string to integer, so how we can update the type and recompute the filled values to the new type? Don't worry, SQL is powerful enough to let you make the change in one sentence with ."}},{"node":{"id":"79af3b04-7c6e-5eca-bdb0-d4e4aadfb60b","frontmatter":{"title":"Working with query params in JavaScript","date":"2019-11-09 09:24"},"fields":{"slug":"/blog/2019/11/09/urlsearchparams","readingTime":{"text":"2 min read"}},"excerpt":"No matter if you work with JavaScript at client or server side, at some point you'll need to work with urls and its query params. As example, I'm currently using react-router in my project, which is an great tool. I can define dynamic routes with path params and easily react-router returns me these params within the  variable and the rest of url information in the  variable, but how can I easily access to query params? There are great libraries for this purpose -like query-string or qs- but the question is: why increase in some more bytes the size of your package when there is a native solution? ðŸ˜„ The ."}},{"node":{"id":"8896a095-5d6d-5109-9965-863da1b7fc56","frontmatter":{"title":"How I migrated my site from Jekyll to Gatsby","date":"2019-10-03 11:06"},"fields":{"slug":"/blog/2019/10/03/from-jekyll-to-gatsby","readingTime":{"text":"9 min read"}},"excerpt":"I think it was a matter of time to make this change. Jekyll was one of the first static site generates and it's awesome but for me, as a JavaScript developer that know little about ruby language, has more sense to stay close JS world. I heard about Gatsby some time ago but never spent enough time to get a good ideas about its philosophy and capabilities. Finally this weekend I decided to make the change. What I found is while Jekyll is extremely good doing one thing --mainly focused on blogs--, Gatsby is a more general solution that can be good for many other things and not only a blog. This post is about my experience in the migration process and how I implemented some features."}},{"node":{"id":"234acf40-fbcb-5207-8b78-f82fe791b118","frontmatter":{"title":"Express API with autogenerated OpenAPI doc through Swagger","date":"2018-10-20 20:31"},"fields":{"slug":"/blog/2018/10/20/express-swagger-doc","readingTime":{"text":"3 min read"}},"excerpt":"In past years OpenAPI has arise as the preferred way to document APIs. In this article we will see how easy is document an API created with NodeJS and Express through the Swagger tools. If you are working in an REST API you more probably will desire to have some API doc where your users could find what are the endpoints of your API, what they do, which parameters they accept and which output they generate."}},{"node":{"id":"265eb0d3-810b-5b53-8418-6e34f5760c5d","frontmatter":{"title":"Joppy, the Tinder for tech recruitment","date":"2018-06-28 14:10"},"fields":{"slug":"/blog/2018/06/30/joppy","readingTime":{"text":"6 min read"}},"excerpt":"TLTR: This post is about Joppy, a new service I'm working on that tries to eliminate the pain currently exists in the communication among recruiters and tech professionals. Let me describe you the current scenario in the recruitment world and, please, any feedback will be welcome. Tech professionals: Wherever I wrote tech professionals I mean any kind of role related with tech companies: software engineers, developers or programmers, manager, product owners, QA, designers, ... It all starts... ...taken a beer and asking your friends: How many connection requests do you receive per week from LinkedIn? All three (two developers and a UI/UX designer) answer the same enough to be annoying. Every tech professional want to have his/her CV updated in LinkedIn, it is a great service, but no one agrees with the myriad of emails asking for connections from recruiters that has awesome job offers from awesome companies. Do you think the job of a recruiter is easy? Well, let me say you are completely wrong. It is not an easy job and often ungrateful. If you think in a more or less important city with many tech companies you can image the competition existing among companies to get tech professional. Currently there are two main things recruiters can do to arrive to candidates: Publish offers in some kind of board and wait candidates applies (we all have in mind web sites that crawls and shows tons of job offers) Make an active search of potential candidates. Recruiters need to use services like LinkedIn, where they can search techies in a given geographical area, that know about X, Y, Z skills and many other options. Once filtered they need to contact each of them where, probably, most of them are not interested in a change or in the position the recruiter is offering."}},{"node":{"id":"f4f8d5a6-446c-5001-8dff-91d437e10c56","frontmatter":{"title":"Using async/await in ExpressJS middlewares","date":"2018-02-15 12:10"},"fields":{"slug":"/blog/2018/03/15/express-async-middleware","readingTime":{"text":"5 min read"}},"excerpt":"If you are not living in a cave for the past year you'll probably know the  keywords are one of the most interesting additions on ES7. It merges the benefits of a sequential syntax with the power of asynchronous programming. In this post we will cover how we must use correctly async functions as express middleware."}},{"node":{"id":"333d8055-865b-583e-baae-4211ae7b65cd","frontmatter":{"title":"Graceful shutdown NodeJS HTTP server when using PM2","date":"2017-08-27 12:10"},"fields":{"slug":"/blog/2017/08/27/graceful-shutdown-node-processes","readingTime":{"text":"5 min read"}},"excerpt":"So you have created a NodeJS server that receives tons of requests and you are really happy but, as every piece of software, you found a bug or add a new feature to it. It is clear you will need to shutdown your NodeJS process/es and restart again so that the new code takes place. The question is: how can you do that in a graceful way that allows continue serving incoming requests?"}},{"node":{"id":"3171d91a-665e-5a38-bec8-945bbe615264","frontmatter":{"title":"Using PM2 to manage NodeJS cluster","date":"2017-08-20 10:34"},"fields":{"slug":"/blog/2017/08/20/using-pm2-to-manage-cluster","readingTime":{"text":"5 min read"}},"excerpt":"The cluster module allows us to create worker processes to improve our NodeJS applications performance. This is specially important in web applications, where a master process receives all the requests and load balances them among the worker processes. But all this power comes with the cost that must be the application who manages all the complexity associated with process managements: what happens if a worker process exists unexpectedly, how exit gracefully the worker processes, what if you need to restart all your workers, etc. In this post we present PM2 tool. although it is a general process manager, that means it can manage any kind of process like python, ruby, ... and not only NodeJS processes, the tool is specially designed to manage NodeJS applications that want to work with the cluster module."}},{"node":{"id":"9e6f4130-15b7-5d2c-a591-ddd13f500345","frontmatter":{"title":"Using cluster module with HTTP servers","date":"2017-08-18 19:18"},"fields":{"slug":"/blog/2017/08/18/using-cluster-module-with-http-servers","readingTime":{"text":"5 min read"}},"excerpt":"The cluster module allow us improve performance of our application in multicore CPU systems. This is specially important no matter if working on an APIs or an, i.e. ExpressJS based, web servers, what we desire is to take advantage of all the CPUs on each machine our NodeJS application is running. The cluster module allow us to load balance the incoming request among a set of worker processes and, because of this, improving the throughput of our application. In the previous post Understanding the NodeJS cluster module I introduced the cluster module and show some basic usages of it to create worker processes and comunicate them with the master process. In this post we are going to see how to use the cluster module when creating HTTP servers, both using plain HTTP module and with ExpressJS."}},{"node":{"id":"e7437c42-3111-5c2f-8e4c-14bc0aa5e986","frontmatter":{"title":"Understanding the NodeJS cluster module","date":"2017-08-12 12:34"},"fields":{"slug":"/blog/2017/08/12/understanding-the-nodejs-cluster-module","readingTime":{"text":"8 min read"}},"excerpt":"NodeJS processes runs on a single process, which means it does not take advantage from multi-core systems by default. If you have an 8 core CPU and run a  NodeJS program via  it will run in a single process, wasting the rest of CPUs. Hopefully for us NodeJS offers the cluster module that contains a set of functions and properties that help us to create programs that uses all the CPUs. Not a surprise the mechanism the cluster module uses to maximize the CPU usage was via forking processes, similar to the old fork() system call Unix systems."}},{"node":{"id":"6c6ecf9c-985e-5267-bcbc-f1a3d5ec46bf","frontmatter":{"title":"fetch API and Express sessions","date":"2016-12-11 09:12"},"fields":{"slug":"/blog/2016/12/11/fetch-api-and-express-sessions","readingTime":{"text":"4 min read"}},"excerpt":"TL;DR fetch API is the successor of XHR and although it's really powerful ( see What is the difference between the Fetch API and XMLHttpRequest?) you should take care of some things, like the fact you are responsible to determine if cookies must be sent to the server."}},{"node":{"id":"3f1ef8dc-7d9b-5590-89ef-98db4252f12d","frontmatter":{"title":"Configuring Atom editor with ESLint and the AirBnB style guide rules","date":"2016-08-14 19:12"},"fields":{"slug":"/blog/2016/08/14/configuring-atom-with-eslint","readingTime":{"text":"5 min read"}},"excerpt":"TL;DR This article demonstrate how to integrate the ESLint tool with Atom editor so our source code be automatically checked, showing linting messages in editor. In addition, ESLint will be configured based on the AirBnB code style rules. Atom & ESLint Atom editor is probably one of the most used text editors (along with SublimeText, Visual Studio Code, TextMate, ...). On his side, ESLint is an open source project, originally created by Nicholas C. Zakas, with the goal to provide a pluggable linting utility for JavaScript. Usually, the way to use ESLint involves the command line, invoking it to check our project's code at some point (for example, before made a build) or automatizing its execution with a tool like Gulp or Grunt each time a file is modified. ESLint also accepts a configuration files, like , where we can define the set of rules we want the tool checks. The issue is, as you can imagine, the number of rules ESLint accepts is really huge. The importance of a style guide In projects with many developers it can be useful define a set of rules that force all of them to code with the same style, that is, use a style guide. The problem with style guides is they are set of good practices-conventions that everybody assumes the rest are applying. As you can image working with assumptions in a big and shared code is not good. Without a tool like ESLint there must be people acting as a police, that is, spending time reviewing the code style and not only the code. Thanks to ESLint this time can be reduced forcing each member of the team to ensure the code follows the same convention rules before committing or pushing to the repository. Besides, using CI tools (like GitHub with TravisCI) we can also check the code style and disable the possibility to merge a branch if the code lint fails. The AirBnB JavaScript Style Guide Creating and maintaining a style guide is not an easy tasks. Hopefully, the awesome people at AirBnB have created the AirBnB JavaScript Style Guide for us that I have chose because of: Works with ES5 and ES6: arrow functions, object destructuring, array spread, ... Includes React and JSX style: one component per file, recognizes stateless vs class component, ... It is based on ESLint. I want to note here the Standard JS project, which defines a set of rules ready to be used in our JS projects. Related with what I have said in the previous section, I want to highlight two sentences written in the main page of the project: This module saves you (and others!) time in two ways: No configuration. The easiest way to enforce consistent style in your project. Just drop it in. Catch style errors before they're submitted in PRs. Saves precious code review time by eliminating back-and-forth between maintainer and contributor. Integrating ESLint with Atom Ok, enough talk and lets start working. We need to make two things: first, configure ESLint in our project (for this we also need to install the AirBnB style guide), and second install necessary Atom plugins to show messages while coding. Configuring ESLint in your project The first thing we need to do is configure ESLint in our project. Remember we are going to use the AirBnB style guide so we need no install the required package and make our ESLint configuration extend from the AirBnB ESLint configuration. Install ESLint locally to your project: . Install the AirBnB ESLint configuration. Following package instructions we need to execute next sentences to install the right package versions and dependencies: Create a  file in the root of our project. We must be sure to include the property  as part of the configuration. Next is a sample configuration file. Note we inherited configuration from AirBnB. In addition, we have added the eslint rules  and  to forces us to write some JSDoc for functions, methods and classes. Right now our project is configured with ESLint and the base set of rules from AirBnB, but it requires we execute ESLint manually or automatize in some way (in the build process). Installing Atom plugins Lets go to configure Atom to automatically lint files and show us message while coding. Be sure you have completed successfully the previous sections. Install the Atom plugin linter-eslint. You are finished :) The plugin will detect automatically the  file in your project and will start linting on the fly the source code showing all the errors and warning.  Conclusions ESLint is a powerful tool that help teams ensuring quality code. On his side Atom is become a great and powerful editor, mainly due the active community and the growing set of plugins. The combination of both tools can improve greatly our productivity so, no doubt and try it !!!"}},{"node":{"id":"f9fdb2de-bab8-586a-aaae-eb7048e2a0e7","frontmatter":{"title":"Introducing Universal Web Applications","date":"2016-08-10 08:32"},"fields":{"slug":"/blog/2016/08/10/universal-applications","readingTime":{"text":"8 min read"}},"excerpt":"TL;DR: This post is the first in a series of articles to talk about Universal (previously known as Isomorphic) Web Applications. The goal of the series is to describe: What an universal web application is? Why are them important? What benefits offers universal web apps? and How to create a boilerplate to start a universal app project. Note, because JavaScript ecosystem is incredible bast and, because we can create an universal web app with almost any combination of framework and libraries, we will use in this series React, Redux and Webpack."}},{"node":{"id":"b8825777-cb02-533e-afe0-1c1dfa228489","frontmatter":{"title":"Resilient PHP applications with Phystrix","date":"2016-07-06 19:32"},"fields":{"slug":"/blog/2016/07/26/resilient-php-applications-with-phystrix","readingTime":{"text":"6 min read"}},"excerpt":"TL;DR: This post talks about how to make our PHP applications more resilient, that is, they must be able to adapt to third party failures and recover quickly from them. You will see why configuring timeouts is not enough to protect your system and what better tools exists. We will explain briefly Hystrix concepts and introduce an alternative for PHP called Phystrix. No matter how well designed be your system, no matter the number, kind or quality of your tests. There is only once thing for sure: your system will fail. Although we can well design, implement and test our systems we have dependencies with third party services: databases, queues, call REST API on another systems, ... In the decade of microservices where dependency/communication among systems becomes a main pilar we need mechanisms to make our systems resistant among third party failures. We need to resilience, that is, recover quickly from disasters. The problem with dependencies In the best case you can be sure your system will work fine but you can make the same assumption for the third party systems you communicate with (another microservices, databases, queues, ...). So the problems arise when some third party services starts failing. This can be because of: The system is near collapse, your requests arrives but they take too much time to be replied. This means each request that arrives to our system is hold until the third party service responds. Because the third party system works slowly we start holding too much connections which could collapse our system too. In addition, although the third party system is near collapse we continue sending requests, so we are not helping to mitigate the problem, we are increasing it. Collapse of a third party service can collapse our system. The system is down. Many drivers tries to establish a connection during a given period of time before raising an exception. Why to wait for a connection if we know the system is down? The classic (and not the right) way to solve The classic way and, a good practice, to mitigate this problem is to configure the timeouts for each library and driver you use to communicate to every third party service. As example, Guzzle allows to set a  when instatiating a : Or the SncRedisBundle for Symfony allows to specify the timeout both for connection and read/write actions: As I said, setting timeouts is a good practice, but it not solves the problem. If the third party is down and we have a timeout of 2 seconds we guaranty our systems will finish the query in two seconds but, why send request and spend 2 seconds while we know the system is down? A robust solution As we talk at the beginning, the goal is to make our system resilient, that is, it must be able to adapt to third party failures and recover quickly from them. This means: Do not call a third party if we know it is down or takes too much time to respond. Fail quickly. If our system receives a request and we can't complete due lack of support from a third party service, we can fail quickly. The client, although it will receive a bad response, will receive a response quickly and our system should be able to attend a new request. You can see how this will avoid a cascade failure of our system. Hopefully, some years ago the Netflix engineers worked in a solution called Hystrix which is so good that has become one of the most famous tools when working with microservices in Java. Hystrix is a latency and fault tolerance library designed to isolate points of access to remote systems, services and 3rd party libraries, stop cascading failure and enable resilience in complex distributed systems where failure is inevitable. Hystrix implements the circuit breaker pattern. Following the electrical circuits analogy, each dependency of our system to a third party service can be seen as a cable with an interruptor. While the communications with the third party works fine, the interruptor is closed (allowing flow the electricity), but when a problem is detected in the third party system (i.e due a timeout) the interruptor is opened making our system impossible to communicate with the third party, which makes our system fail quickly when a dependency fails. A robust solution for PHP After looking some libraries I finally decide to use Phystrix, a Hystrix port to PHP made by oDesk (now Upwork). Following Hystrix design, Phyxtrix requires all the actions we want to make against a third party service (querying a database, inserting into a queue, etc) must be encapsulated as a command (see the command pattern). The library offers and abstract command class from we can inherit when creating our commands. It is up to us to implement the  method responsible to make the real action (the call to a service, the insert into database, etc) and optionally the  method that returns a result if the third party is not available. The good part is each time a command is executed, the base command class collects metrics (like the number of failed call to a third party) and is responsible to manage the circuit state (open or close) depending on the current metric values. Note Phystrix stores all the metric in APC, so you should have this extension enabled. Additionally, the people from oDesk implemented two more tools: phystrix-bundle: A bundle for Symfony2 that can help us integrate Phystrix into our Symfony projects. phystrix-dashboard: Some classes that helps creating an endpoint in our application to serve the metrics stores by Phystrix. This endpoint can be added to the hystrix-dashboard tool to monitor our metrics in almost real time. hystrix-dashboard Conclusions Our systems has dependencies to other systems we can't control. Setting timeouts in our connections is a good practice but it is not enough. Hystrix is a tool that implements the circuit breaker pattern, which can help our systems to be more resilient. Phystrix is a Hystrix port for PHP. It is easy to integrate in our PHP applications and protect against latency, fault tolerance and cascade failures when working with third party systems."}},{"node":{"id":"d290be60-47df-5c9d-807c-485640183f23","frontmatter":{"title":"Symfony, images and S3","date":"2016-03-25 08:09"},"fields":{"slug":"/blog/2016/03/26/symfony-and-s3","readingTime":{"text":"6 min read"}},"excerpt":"Paraphrasing the movie title Sex, lies and videotape, this post is related on how I configured my symfony project to work with images (including thumbnail generation) and store all them on Amazon S3 service. There are are libraries and bundles to work with images and also others to work with S3, but the combination of all them can be a tricky experience with not much documentation out there. In addition, there is also one more challenge to achieve and, that is, while developing I want to store images locally (in a directory) but when deployed I want to use S3 storage. Currently I'm working on a project where users can upload photos. The application allows users to create collections, drag and drop images, order them and finally upload to the server. In addition, the user can explore his/her collections, browse images and download collections in a single ZIP file. All this having in mind: While developing locally we want to store images in the local server folder. In staging or production environment we want to use S3. Original images must remain private, while the thumbnails must be public to be included in the application web pages. We need to generate thumbnails with different sizes. When a user access to a collection a list of small thumbnails are shown. When user clicks an image a medium thumbnail is presented. When user downloads a collection the ZIP file must include the original images. So, in summary, we need to deal with image upload, thumbnail generation and S3 service. Uploading images For image uploading we have used the VichUploaderBundle. Uploading images isn't a secret but can involve some extra tasks. The VichUploaderBundle helps working with file uploads that are attached to ORM entities, that is, it is responsible to move the images to some configured place and attach it to your entity. In addition, we want to store images in folders classified by user and collection, something like , where  and  are identifiers. A nice feature VichUploaderBundle offers is the possibility to attach the so called directory namer or file namer that determines the final name for the upload file. This way when a file is uploaded, given the current user and the selected collection, we determine dynamically the target folder where the bundle must store the image. Note the ORM entity only has the image file name. The path to the file is computed through the specified directory and/or file namers. For this reason, the bundle also includes the methods require to get the absolute path to a file given the file name stored within the entity. Generating thumbnails To generate thumbnails we have used the LiipImagineBundle bundle. With it, when you reference an image within your templates you don't get the original image but a new one obtained applying some filters. Next line shows how to include an image in your twig template obtained after applying a  configuration: The good thing is LiipImagineBundle generates the thumbnails when images are first time accessed and stores them in a cache folder for next calls. Abstracting the file system The issue is we want to upload images and generate thumbnails into a local folder at development time and to S3 when running in staging or production. Hopefully for us there is the Gaufrette bundle, which is an abstract filesystem. It offers a common interface to read/write to different filesystem and a bunch of implementations to work against the local filesystem, an FTP server, Amazon S3 service, ... and many more. Putting it all together Arrived here, the main question is how to configure the three bundles to work together, in summary: We want to abstract the filesystem to work locally while developing and with S3 in production. We need to upload images. We need to generate thumbnails for uploaded images and store them in a cache folder to be later server. We have divided the configuration between the  file and the . The first contains the configuration for the previous three bundles ready to work locally. The second overrides some propertires to work in production, using S3. The first point is to configure the Gaufrette bundle to abstract our filesystem. Next is the configuration in the : Compare with parameters we override in the . Note for production you need to define an AWS-S3 service which I do not include here. We define a  filesystem which by default uses a  adapter and in production uses an  one. Next step is to configure the VichUploaderBundle bundle. Hopefully it is designed to integrate with Gaufrette so it is easy to specify how to upload files through gaufrette. Next is the configuration: As you can see we are specifying we want to use gaufrette with  and the upload destination is the previous defined gaufrette filesystem . This means all images will be uploaded through the Gaufrette filesystem to that destination. Note, within the target filesystem, the final folder and file name are determined by a custom directory namer we have implemented ( which adds the user ID to the path) and the file namer  offered by Gaufrette, which assigns a unique name to each file. Finally, we need to configure the LiipImagineBundle bundle. Next is the configuration used for local development. We need to specify the cache folder where to generate the thumbnails in adition to our filter, that will generate with size  and half quality: Main properties to configure are the and the . The first one uses the stream  that uses gaufrette filesystem. The second uses the resolver  that we have configured to use the local folder . For production, configuration changes slightly. Here we override the resolver to generate cache files through the resolver  which points to S3 bucket: Conclusions VichUploaderBundle, LiipImagineBundle and Gaufrette are three great Symfony2 bundles. The configuration to make work all them can by tricky so hope this post can help others. While VichUploaderBundle is designed to work with Gaufrette, and its configuration is almost trivial, LiipImagineBundle is not and requires some extra tasks. For LiipImagineBundle we need to configure its main components, which are the cache and the ."}},{"node":{"id":"66ce5730-e55d-5864-9f36-be72f4229d10","frontmatter":{"title":"Closing 2015","date":"2015-12-31 18:14"},"fields":{"slug":"/blog/2015/12/31/Closing-2015","readingTime":{"text":"2 min read"}},"excerpt":"2015 is finishing. Its 18:15h while writing these lines. Looking back to this year lot of feelings mixes in my mind, some of them great and some sad. But live continues and we can only go forward. At professional level the most important fact was leaving Servei MeteorolÃ²gic de Catalunya (meteo.cat) after nine years. I leave great workmates. We made some incredible things and, in the past year we work in some nice projects (a new website, a mobile ready web and an API to access weather data). Although probably the thing what I'm most proud with, as a team leader, was the fact to help creating a positive and constructive environment, always looking to learn and improve. Anyway, decisions are not easy to take and never likes to everybody. Well, I'm human like anyone, I can be wrong, but do not regret from anything I was done. You have enemies? Good. That means youâ€™ve stood up for something, sometime in your life. - Winston Churchill A man with no enemies is a man with no character. - Paul Newman This year also start working at CartoDB, a young and really motivated company. I have been the last couple of months diving into code, learning and helping. I can't say much more, but the fact we are working on something really awesome for this new year :) At personal level this was a really hard year. The death of my father seems something a can't overcome. After a suddenly and aggressive cancer he passes away on April. The few months he lived after cancer was detected were a real hell for the family, and specially for mother. He always tried to have mental strength but seeing yourself deteriorating at giant steps is hard enough to make you fall and seeing someone you love dying a bit more every day, while trying to demonstrate strength, is something that is going accumulating in your mind. Simply writing these lines tears comes to my eyes. He teach me to have an open mind. He was the one that shows me what principles mean. I always thought if my father hadn't been my father we had been great friends. He always was proud about. See you some day friend ;) Live continues and we must continue going forward."}},{"node":{"id":"459c988f-d477-508a-93a4-d8a83a3c3812","frontmatter":{"title":"Reading very big JSON files in stream mode with GSON","date":"2015-10-23 15:19"},"fields":{"slug":"/blog/2015/10/23/reading-json-file-in-stream-mode-with-gson","readingTime":{"text":"5 min read"}},"excerpt":"JSON is everywhere, it is the new fashion file format (see you XML). JSON format is mainly used on REST APIs because it is easy to read by JavaScript  (JSON means JavaScript Object Notation) allowing to develop client side application. In Java and, similarly to the old days of XML, we have different ways to read JSON files: object model or streaming way. No one is better than other, they are simply designed for different needs and situations. The object model way works loading the whole file in memory and translating each JavaScript object to a Java object containing all the properties, array objects, etc. It is similar to the DOM way to read XML files. On the other hand, the stream way reads the file byte by byte and allows to apply actions when an object starts, an array ends, etc. It is similar to SAX way to read XML files. There is a third way to read a JSON file, similarly to StAX with XML, that combines the streaming way to read with the object model. For example, we can read a file in stream mode and when found an object start then read the whole object into memory. Which method is better depends on your needs. If your JSON is small the object model is great because you can load all the data and work as a normal Java objects, searching within an array, iterating, etc. When the file is really big you'll probably don't want to load it all into memory, so the streaming model is the best choice. The scene We are working on an API implemented in Java and one of the operations requires to open a big JSON file (about 10Mb) an returns an object identified by a given string. The file in question is formed by an array of objects, tons of object, and it has no sense to read the whole file and create tons of Java objects into memory only to return one. So, this is a good scenario to read the JSON file in stream mode. The code Before to continue it is worth to mention the code you will see here is available at java-json-examples repository. I have generated a 2.5MB JSON file using the mockjson tool. The data file is formed by an array ob person objects. Each person has an , , a  status and a list of  and : {% highlight json %}\n[\n  {\n    \"id\" : 0,\n    \"married\" : true,\n    \"name\" : \"George Moore\",\n    \"sons\" : null,\n    \"daughters\" : \n      {\n        \"age\" : 25,\n        \"name\" : \"Elizabeth\"\n      },\n      {\n        \"age\" : 28,\n        \"name\" : \"Nancy\"\n      },\n      {\n        \"age\" : 9,\n        \"name\" : \"Sandra\"\n      }\n    \n  },\n  ...\n]\n{% endhighlight %} GSON We are using GSON to read JSON files in Java. Take a look to the wikipedia link so you can see some of its main features. The other one great library to work with JSON data is Jackson. Both have similar features and performance. Our  model class When GSON reads JSON data it allows to unmarshal it to a given Java class. For this purpose we have created the  class which will store all the previous information (for the sample we are only stoting the person  and ): {% highlight java %}\npublic class Person {\n    private int id;\n    private String name; }\n{% endhighlight %} Reading using object model Next code shows how to read the JSON file using the object model. Remember, we are loading the whole file in memory converting data to  java class. {% highlight java %}\npublic static void readDom() {\n    BufferedReader reader = null;\n    try {\n        reader = new BufferedReader(new FileReader(file));\n        Gson gson = new GsonBuilder().create();\n        Person[] people = gson.fromJson(reader, Person[].class); }\n{% endhighlight %} The magic occurs within the line: . We are telling GSON to read the file and return an array of  objects. From here, if we want to return a given person we need to find it within the array. Let's take a look how we can do the same using the stream mode. Reading using the stream mode What we really are going to do here is to use a mixed mode between stream and object model. We are going to read file in stream mode and each time we found the start of a person object we are going to unmarshal it using the object model and we will repeat the process until we found the desired object. {% highlight java %}\npublic static void readStream() {\n    try {\n        JsonReader reader = new JsonReader(new InputStreamReader(stream, \"UTF-8\"));\n        Gson gson = new GsonBuilder().create(); }\n{% endhighlight %} With this approach we are loading all the objects to memory but one by one and not the whole file at once. Conclusion We have seen that JSON files, like XML, can be read with different techniques. Object model, stream mode or a mix of both. It is up to you to chose one depending on your needs. Object model allows to read a whole file and offers greater abstraction, because you can unmarshal data to your custom Java object model. Stream mode allows to read big files consuming fewer memory. As a cons, it implies a more low level reading but can be improved mixing both models (like in the example)."}},{"node":{"id":"fc0beb5e-2192-594f-9fb9-615f88e58ace","frontmatter":{"title":"Webpack, not another task runner tool","date":"2015-10-15 21:50"},"fields":{"slug":"/blog/2015/10/15/webpack-not-another-task-runner-tool","readingTime":{"text":"2 min read"}},"excerpt":"It seems we are living an gold era about JavaScript and front end world with a myriad of frameworks, language improvements and, what is related to this article, build systems, tasks runner or whatever you want to call them.\nWe have adepts to Grunt, firm believers of Gulp or purists preferring the use of old fashion npm scripts way. Well, I'm sorry for all of you but there is a new kid on the block and it is (IMO) a really strong competitor. It's name is webpack and it is a module bundler. OMG !!! A module what? What is webpack ? Webpack is a module bundler. It has nothing to do with a tasks runner, although in many cases can substitute the need of gulp or grunt. Webpack understands about modules and its dependencies (among JavaScript files, CSS or whatever) and generates assets. Probably you don't understand the importance of the last sentence, so I repeat it again: Remember webpack understands about modules and its dependencies and is good to generate assets from it. That is probably the main impact I see when developing with webpack. To get all its potential you need to change your mind from programming a set of JavaScript files, that finally and concatenated and minimized, to a set of modules, that exports variables and has dependencies among them. A brief presentation Here I present a short slideshow I prepared to introduce webpack to my team. Any feedback will be appreciated. You can also view at slid.es The two samples present in the slideshow are available at github at the webpack-presentation repository."}},{"node":{"id":"17aa8962-ef6e-517c-9467-5912117889fa","frontmatter":{"title":"Git, a short introduction with some pictures","date":"2015-09-23 08:14"},"fields":{"slug":"/blog/2015/09/23/git-a-short-introduction-with-some-pictures","readingTime":{"text":"1 min read"}},"excerpt":"This is a short introduction about Git version control system I made some time ago describing the main topics. Currently, Git is probably one of the most powerful and most used version control systems, so never is late to start with it. You can also view at slid.es"}},{"node":{"id":"604ed1b9-f1ca-53a5-b9c1-cda5afe4f898","frontmatter":{"title":"Specification pattern for NodeJS","date":"2015-09-21 22:14"},"fields":{"slug":"/blog/2015/09/21/specification-pattern-for-nodejs","readingTime":{"text":"4 min read"}},"excerpt":"Although the specification pattern is mainly use in DDD to check business rules, I think the idea of combine rules offers great flexibility in any application architecture, it is suitable for any kind of validations, simplifying and improving reusability and making code clearer. Because of this, some days ago I started working on an implementation of the specification pattern for NodeJS. The code is freely available at github repository and also installable via npmjs. The specification pattern There are tons of good documents and tutorials about the pattern, so I don't want to extent too much here. The best source of information, IMO, is the Eric Evans big blue book Domain-Driven Design: DDD The specification pattern is powerful enough to be used for: validations, queries and creation of objects that satisfies some criteria. So, take into account this post is only related to the first options: the validation of objects that satisfies some critaria. An specification is a piece of code that checks if a business rules is satisfied or not. For example, given a bug tracking system we can create two specification to check if a software project: has few issues if the number of issues reported last month is less 10, and is updated project if the date of the last solved issued it not beyond a week. The great of specifications is we can easily combine them to create complex rules reusing the code, for example, we can create the specification quality project that means a project has few issues and is an updated project. Wikipedia has a nice image showing an UMl diagram class about the specification patter: UML specification pattern We can see a specification is any interface that implements the  method and has the ,  and  method to chain specifications. How to use the NodeJS implementation ? I have created two implementations of the pattern: asynchronous and synchronous versions. The synchronous version is fine for those in-memory validations, for example when you do not require query a database. The asynchronous version, on the other hand, is suitable for those cases in which the validation depends on an asynchronous source, like a file, a query to an API, etc. The first step to use the implementation is to include the required version (synchronous or asynchronous): For each business rule (or validation) you need to check, a specification must be created. Next code creates a specification that checks if a number is greater than the one indicated at the specification: Later, to use the previous specification: The base class  offers the ,  and  methods we can use to chain specifications and build complex ones. For example: The asynchronous version is suitable if you need to check agains an asynchronous source, like a database, files, etc. The only difference is the way to implement the  method, which must be use a callback, for example: and to use it you can make via the callback: Chaining specifications works in the same way as the synchronous version, simply remember the only difference is the way to use the  method: Conclusions The post presents a dual implementation for NodeJS, synchronous and asynchronous. There is no reason to use design patterns in a multi-paradigm language like JavaScript. Specification pattern can help when working with validations, simplifying reusability and allowing validations chaining through specifications."}},{"node":{"id":"9fd50913-90e6-5b23-8d72-375e323f81d3","frontmatter":{"title":"I'm working on ClydeIO","date":"2015-09-14 17:48"},"fields":{"slug":"/blog/2015/09/14/i-m-working-on-clydeio","readingTime":{"text":"5 min read"}},"excerpt":"ClydeIO is an open source API gateway and management layer based on nodejs. It is extremely flexibly, configurable and simply to extend. It is designed to simplify the development of new APIs (or simply improving existing ones) adding authentication, logging, rate limiting, etc. Note, the project is currently a proof of concept (I'm currently working to apply it in a real system) and most of the developed filters are basic implementation to demonstrate its usefulness. What is an API gateway and why I need one? The most important part when designing and implementing an API is to model your business correctly and offer a set of well defined operations accordingly with them. Unfortunately, that is only an small part of the job and it is not enough to ensure the success. As a real World system you require to secure your API, store logs, apply rate limits, etc. The task of publishing an API becomes much more complex than understanding your business, you have entered the world of security, monitoring and... the unknown !!! An API gateway is a single point of entry responsible to apply actions (like security or logging) before redirecting the request to your real-do-the-job API. We can see the gateway as a kind (or mix) of firewall and proxy and is really useful implementing microservices.  Thanks to ClydeIO you can spend your efforts implementing your business API leaving the rest of things to the gateway. The glory of ClydeIO is its simplicity and its easy to extent with new filters like: Secure an existent API Log access to any resource Rate limiting Filter request (allow/deny) depending on the query parameters Cache data or whatever you need  Because it is based on node we can use the myriad of awesome node packages out there and integrate within your filters.  Why a new system instead contribute to an existent one? I was looking for similar projects before start ClydeIO. There is plenty of services that provides same functionalities (and many more) as well as many projects with a great maturity level,Â but no one satisfies my needs. Services implies a cost for its usage that, sometimes, can be hard to calculate and in some cases requires you adaptÂ your systems (your business API) to accommodateÂ to the service requirements. Other software projects means you must be comfortable with the technology they are implemented with, mainly its programming language and database used to store configuration and information. One thing I saw in common in most of the software projects is the fact they do what they do, that is, they are prepared to make many things, do it well but are not allowed to extend the gateway easily with new requirements users can have. They are designed to make the most common things: rate limiting, security, logging, etc but it is hard to know how we can extend the gatewayÂ to send us an email when there was more than ten invalid accesses. In addition, I found some of them really complex to configure, based on monster XML configuration files. Once last comment on why I created ClydeIO: to take advantage of the node modules. There exists other API gateways implemented using NGINX server, lua, go or python language but nonetheless implemented with node. To be honest I must point here the StrongLoop LoopBack API Gateway product. Current status ClydeIO is currently a proof of concept and I have implemented a bunch of filters to test its capabilities. Currently all configuration is provided via a JSON file. That's nice and simply but not much secure when working with authentication filters that needs specify users and passwords or with a real scenario that requires manage hundred of users. Because of this I'm currently working hard trying to create the configuration module, responsible to manage the whole configuration, and designing to be easy to implement for different backends: memory, redis, mongodb, postgresql, ... I have great feeling about ClydeIO's possibilities but to be honest it is currently a personal side project I write on my few free time. I have no contributors neither sponsors. So, if you arrive to this page and are interested in the project feel free to contact with me and start helping with your money or time :) Documentation I have create the ClydeIO github organization to host all the related projects related with ClydeIO. We can differentiate among the core project, so called clydeio too and the rest of projects that are clyde's filters. The current core project documentation can be found at the project's wiki: https://github.com/clydeio/clydeio/wiki. It will probably change soon, once finished the configuration module, but the concepts remains the same. Contributions As a said, for the moment this is a personal project I develop on my free time. So don't hesitate to contact with me for any kind of support and help."}},{"node":{"id":"eb5405e2-96c8-51a3-a28f-048bf1b2a557","frontmatter":{"title":"How to read from a writable stream (http.ServerResponse) in Node","date":"2015-08-31 21:05"},"fields":{"slug":"/blog/2015/08/31/how-to-read-from-a-writable-stream-httpserverresponse-in-node","readingTime":{"text":"3 min read"}},"excerpt":"I'm working on a personal side project (when I have free time to spend on) where a bunch of middlewares are chained to do something awesome (Take a look at ClydeIO. Note it is currently a proof of concept). Remember a middleware is nothing more than a function that receives three parameters: the , the  and the  function: The  parameter is an instance of , a readable stream, while the  parameter is an instance of , a writable stream (something similar to Java servlets). Usually a middleware reads the request, optionally attach more data or modifies it, maybe writes some content on the response and continues the execution in the next middleware invoking the  function. If any of the middlewares writes content and invokes the  method the response is sent to the client and middleware chain is aborted. Note, I'm working with Connect and not Express, but the concepts are the same.\nExpress uses the  method to write content, which is based in the  and  core node methods. Also Express extends with request and response object with its own methods. Now, suppose in a middleware you need to get the current content (the response body) other middlewares has been written. The response is an output stream and it is designed to have write oriented operations: write content, write headers, etc but not read operations. So how we can read the content written on a writable stream? Do not confuse the response reference we have in a middleware (or simply in a  listener), which is a writable stream, with the object we obtain when using . With  we obtain an instance of  and when listen on it for the  event we get a , a readable stream. That is, the response we obtain is a readable stream where we can read data sent from the server. In a middleware we are the server and are responsible to write data in an output/writable stream. The solution I found is override the  method. The  method is defined by the  interface and it is mandatory each writable stream class implements it. So, they idea is to override the method in a way we can store the data is written and later invoking the parent method so they what usually do: Now, the second middleware can read all the chunks of data any other middleware writes to the response and continues the normal execution of the  function invoking the original version. Note, if you need to access the response headers the solution is similar but, in this case, you need to override the methods ,  and ."}},{"node":{"id":"b066c5d9-1787-5630-ba9c-e5456666493d","frontmatter":{"title":"Using random unsplash images on your website","date":"2015-08-17 22:08"},"fields":{"slug":"/blog/2015/08/18/using-random-unsplash-images","readingTime":{"text":"2 min read"}},"excerpt":"Recently I updated my we page and one of the nice features I included on it is the fact a random image is placed in the header for each page. These images are obtained from the great unsplash, a free (do whatever you want) high-resolution photos project. As its slogan says, unsplash contains tons of really good images, both by its resolution and the photographies. To embed the unsplash images in my web site I used the unsplash.it service, its slogan says Beautiful placeholders using images from unsplash.  It was created by  David Marby and Nijiko Yonskai and the code is publicly available at the github unsplash-it repository (if you are interested it is a NodeJS based project). But what does exactly unsplash.it? Basically it returns images from unsplash project with some steroids. Retrieve an image indicating the desired width and height: https://unsplash.it/500/400 Using a square image: https://unsplash.it/500 Get a random image: https://unsplash.it/500/400?random or maybe grey styled: https://unsplash.it/g/500/400?random Obtain a list of available images: https://unsplash.it/list And retrieve a given image: https://unsplash.it/500?image=123 Maybe a bit blured: https://unsplash.it/500?image=123&blur And finally, cropping if desired: https://unsplash.it/500?image=123&gravity=east Yeah !!! unsplash.it is nice service easy and free to use."}},{"node":{"id":"ff5368ee-8533-5694-8d71-f714e35b8881","frontmatter":{"title":"Migrating from WordPress to Jekyll","date":"2015-08-11 11:02"},"fields":{"slug":"/blog/2015/08/06/migrating-from-wordpress-to-jekyll","readingTime":{"text":"3 min read"}},"excerpt":"WordPress is awesome, an incredible project with thousands of plugins that does not need any presentation. What start as a blogging platform has become a powerful framework to build almost anything. All that is fine, but... recently I migrated this blog from WordPress to Jekyll. The problem for me is WordPress starts as a quick solution to have a blog but has increasingly become a two big resource to administer. I have installed plugins to manage spam, to limit access login (for security reasons), to share content on social networks, to highlight source code, to add Google Analytics code, etc. I have a tech blog. I write about programming, libraries and how to do things, accompanied by sample code. WordPress WYSIWYG editor is great but not agile to write code. On the other side the test view of the content is poor and becomes affected by the visual view each time you change between tabs. Jekyll is much simpler than WordPress. It is much more less powerful than WordPress in many aspects but if offers me what I need in a more simpler way. Jekyll is an static site generator. Opposite to WordPress, written in PHP, where each request implies a query to get data, apply some process and finally return the resultant page, Jekyll has a completely different philosophy. With Jekyll you write content in markdown syntax and applying some rules, mainly a front matter section on pages and posts. Once you agree with your content Jekyll compiles them and builds an static version of all your content ready to be hosted. For those with a GitHub account, remember if you put all the content on a repository there is no need to compile because GitHub does it for you each time you push commit. Yes, you write directly in markdown syntax on any text editor, there is no visual editor like in WordPress, but it is exactly what I need: to have as much control as I can over what I write. In fact, the writing process results quickest than using the WYSIWYG mode in WordPress, especially when I require to write code. The migration process To be honest I must admit in my case it was a bit traumatic, in part because I'm a bit tiquismiquis with my things. The steps about the migration were basically: Export your WordPress content on Tools > Export menu.  Use jekyll-import tool to create a jekyll site from the WordPress export file. The tool creates all the posts and pages but unfortunally attach to much information on the front-matter section I don't like neither want. So I must apply many modification manually on each postand, in most cases to translate from HTML to markdown syntax (using the only to-markdown translator tool). Migrate all WordPress comments to Disqus platform. For this, I need to install the Disqus Comment System plugin and have a configured account. Once you configure the plugin all the comments are migrated automatically. Here the step was a bit more cumbersome because the new blog is in a different URL. So I need to export all the Disqus discussions, update manually all the URLs and import again in the system.  Chose a jekyll theme and adapt a bit for my needs. I chose the Kasper, a Ghost's theme ported to jekyll. I changed the theme to include some more header buttons (one for each page) and add random images, from the unsplash project using the nice unsplash.it service. The result is I have a blog I feel really comfortable :)"}},{"node":{"id":"edb915db-95f8-559d-b8b2-85f8730b807e","frontmatter":{"title":"Working with different environments on jekyll","date":"2015-08-04 18:02"},"fields":{"slug":"/blog/2015/08/04/working-with-different-environments-on-jekyll","readingTime":{"text":"3 min read"}},"excerpt":"Jekyll is an open source static site generator. It allows writing content in markdown (also HTML) using some rules, like adding some front matter on pages or posts. Later jekyll compiles all the code and generates an static version for each page and post. The benefits of having an static site are mainly speed. Contrary to other blog engines like WordPress, where each request requires server works querying data, processing and returning the page, jekyll only does that work once, when the static site is built. Jekyll is also well known by the fact it is used by GitHub. If you host your jekyll posts on a GitHub repository you don't require to compile them because GitHub does for you each time you make a commit. If you are interested on this topic see pages and take a look at pages basics. A few days ago I migrate this blog from WordPress to Jekyll. Note its source code, with all the post I wrote and will write al publicly available at https://github.com/acanimal/acuriousanimal-blog.github.io. The method I follow to write is: I write in my local version of jekyll. Once I finish an article... I run jekyll locally to see all looks fine. If all is fine... I commit the changes to the GitHub repository. This makes GitHub compiles the posts and generates the same content like me. Something I missed from the beginning was the possibility to have a different configuration depending if on the environment. When working locally I want all links and images point to my local computer, while when I upload content to GitHub I want links to be relative to GitHub hosting. Hopefully this is really easy to achieve using more than one configuration file. I have a main  where all variables are set. Next is part of my current configuration file: In addition, I have a  file I only use when working locally. This files contains all variables I want to redefine when working locally. For example: Jekyll commands allow to specify more than one configuration file. We simply must remember a variable existent in a configuration file can be overridden with a value on the second file. Having this in mind, I run jekyll locally with the next command: This produces the value of  specified at  becomes overridden by the value of  variable specified at ."}},{"node":{"id":"0c371987-6ed1-51a8-9c67-5423e3096996","frontmatter":{"title":"Generate and host your own raster tiles customized with Mapbox Studio","date":"2015-07-26 16:47"},"fields":{"slug":"/blog/2015/07/26/generate-and-host-your-own-raster-tiles-customized-with-mapbox-studio","readingTime":{"text":"9 min read"}},"excerpt":"If you have never saw maps hosted in Mapbox platform you would probablyÂ agree onÂ the quality of its designs.Â The business of Mapbox is to host and server geospatial data. For this reason, all the great tools Mapbox facilitates are oriented to help their users to prepare and work with their data. One of the providedÂ toolsÂ isÂ Mapbox Studio.Â Mapbox Studio (MbS) is a desktop application that allows to create CartoCSS themes that are later used to generate raster tiles. Briefly explained, what MbS does is to download OpenStreetMap data in vector format and render it on the fly applying the specified CartoCSS style. The result of working with MbS is not a set of tilesÂ but a style, that is, a set of rules that express which colour must be used to render roads, at which levels must labels appears and with which size, which colour must be used for ground, etc. This style can be later uploaded to Mapbox platform so that raster tiles were generated on the cloud and we can consume the tiles paying for the service.Â (Hope one day I can contract their services, they deserve by their great job). The question we can make us is: how we can generate the raster tiles locally from a given MbS style? Well, this article is about that. Continue reading. Working with Mapbox Studio and create your custom style Let's start from the beginning so download Mapbox Studio application and install on your system. Once installed execute it and you will be asked to be connected to the Mapbox platform. There are two main reasons why Mapbox requires you to register as a user. First, the power of the platform is on the cloud and the goal is you upload all your data to the servers. That includes the styles you create. Second, MbS retrieves data in vector format from Mapbox servers. When you register as a user you get an API token that identifies your requests. Each time MbS makes a request to extract data it has your token that identifies you as user. This way Mapbox can control if anyÂ user is making a bad usage of their platform.  Once logged in you will be allowed to create new map styles. The easiest way is to start using one of the starter styles created by the great Mapbox designers:  Here we have chose the Mapbox Outdoors style. In the image you can see the style code (CartoCSS which is inspered by CSS) and the resultant tiles obtaining from painting the vector information with the given style rules: CartoCSS is a Mapnik stylesheet pre-processor developed by MapBox and inspired by Cascadenik. It is like a CSS language specially developed to style maps.  Store the style with a new name somewhere on your computer, for example, . If you look at your disk you will see a  folder has been created containing a bunch of files that defines the style rules (take a look they are not dangerous). Finally, modify some properties, for example  or  colors and save to see the result:  Great !!! You just have created your first custom style. Generating raster tiles from MbS style Looking for a solution I discovered the tesseraÂ and tl tools.Â Tessera is a node based command line application. It is based in some modules from mapbox (concretely tilelive) plus others implemented by the author (Seth Fitzsimmons). The result is we can execute tessera passing a MbS defined style, open a browser pointing to a local address and see a map with the raster tiles generated with our MbS style. Similarly, tl is a node based command line tool we can execute, passing a set of options, to generate a MBTiles file or a pyramid of tiles following the well known  format. I know about both tools at the articleÂ Converting Mapbox Studio Vector Tiles to RastersÂ from Azavea Labs. How to install the tools? NOTE: You need to have NodeJS installed in your system, along with the npm package manager command line tools. I don't like to install global node packages (or at least more than the necessary) so I'm going to install the previous tools in a custom folder: {% highlight bash %} mkdir tiletools\ncd tiletools\n{% endhighlight %} Inside the directory execute next sentence, which install the  and  packages among others: {% highlight bash %} npm install tessera tl mbtiles mapnik tilelive tilelive-file tilelive-http tilelive-mapbox tilelive-mapnik tilelive-s3 tilelive-tmsource tilelive-tmstyle tilelive-utfgrid tilelive-vector tilejson\n{% endhighlight %} You will see a hidden directory namedÂ  has been created which contains some subdirectories with the same name as the previous packages. Running tessera Let's try to run tessera for the first time. Because it is installed as a local node module execute: {% highlight bash %} ./node_modules/tessera/bin/tessera.js Usage: node tessera.js uri options uri     tilelive URI to serve Options:\n   -C SIZE, --cache-size SIZE          Set the cache size (in MB)  10\n   -c CONFIG, --config CONFIG          Provide a configuration file\n   -p PORT, --port PORT                Set the HTTP Port  8080\n   -r MODULE, --require MODULE         Require a specific tilelive module\n   -S SIZE, --source-cache-size SIZE   Set the source cache size (in # of sources)  10\n   -v, --version                       Show version info A tilelive URI or configuration file is required.\n{% endhighlight %} Tessera requires you pass an URI so it can server its content. It accepts URIs from Mapbox hosted file, Mapnik, Tilemill, Mapbox Studio, ... Repeat again indicating the path to our previously created style indicating the protocolÂ . {% highlight bash %} ./node_modules/tessera/bin/tessera.js tmstyle://./customstyle.tm2\nListening at http://0.0.0.0:8080/ /Users/antonio/Downloads/tiletools/nodemodules/tessera/server.js:43\n        throw err;\n              ^\nError: A Mapbox access accessToken is required. `export MAPBOXACCESS_TOKEN=...` to set.\n...\n{% endhighlight %} First seems tessera is working at port 8080 but later we get an error about . If you remember from the first section, Mapbox requires all the requests be signed with the user token. So, you need to get the access token from your account and set it as environment variable before execute tessera: {% highlight bash %} export MAPBOXACCESSTOKEN=yourtokenhere\n./node_modules/tessera/bin/tessera.js tmstyle://./customstyle.tm2\nListening at http://0.0.0.0:8080/ /Users/antonio/Downloads/tiletools/node_modules/tessera/server.js:43\n        throw err;\n              ^\nError: Failed to find font face 'Open Sans Bold' in FontSet 'fontset-0' in FontSet\n{% endhighlight %} We are close to make it work. The problem now is our MbS style is using a font we have not installed in our system. One easy, but brute force, solution is to install all Google Web Fonts on your system. For this purpose you can use the Web Font Load installation script. In my case I have installed them in the user's fonts folder . Once fonts were installed try executing tessera again: {% highlight bash %} ./node_modules/tessera/bin/tessera.js tmstyle://./customstyle.tm2\nListening at http://0.0.0.0:8080/ /Users/antonio/Downloads/tiletools/node_modules/tessera/server.js:43\n        throw err;\n              ^\nError: Failed to find font face 'Open Sans Bold' in FontSet 'fontset-0' in FontSet\n{% endhighlight %} That' s a bit strange, we have just installed the fonts but they are not found. What is happening? Well, tessera uses mapnik to create the raster tiles and it looks for fonts in the folders specified byÂ the environment variable , so let define the variable: {% highlight bash %} export MAPNIKFONTPATH=~/Library/Fonts/\n{% endhighlight %} and execute the script again: {% highlight bash %} ./node_modules/tessera/bin/tessera.js tmstyle://./customstyle.tm2\nListening at http://0.0.0.0:8080/ /Users/antonio/Downloads/tiletools/node_modules/tessera/server.js:43\n        throw err;\n              ^\nError: Failed to find font face 'Arial Unicode MS Regular' in FontSet 'fontset-0' in FontSet\n{% endhighlight %} OMG !!! This seems a never ending story. Now we need to install the Arial Unicode font. Look for it,Â install in your system and execute tessera again: {% highlight bash %} ./node_modules/tessera/bin/tessera.js tmstyle://./customstyle.tm2\nListening at http://0.0.0.0:8080/\n{% endhighlight %} Great !!! It seems tessera is working fine. Let's go to open our browser pointing to  and see the result:  A map implemented using Leaflet web mapping library is shown, rendering raster tiles that are created in the fly. Look at the console to see the tessera output information:  We can see how tiles at current zoom, the zoom level 8, has been generated. At this point we have tessera working but what about generate a local pyramid of tiles for a given zoom levels and a given bounding box? Generating a custom pyramid of tiles with tl command line tool Before continue we need to know which bounding box we want to generate, the whole World? or only a piece. In my case I want three zoom levels (7, 8 and 9) wrapping Catalonia. There are some online tools you can use to get the bbox of a region, but one I like it the Bounding Box Tool from Klokan Technologies. The tl tool can run three main commands but are only interested in the copy one, which copies data between two providers. In our case the MbS style is one provider and the file system is the other. Run the tl command to see the available options: {% highlight bash %} ./node_modules/tl/bin/tl.js copy --help Usage: node tl.js copy   options source     source URI\nsink       sink URI Options:\n   -v, --version                 Show version info\n   -b BBOX, --bounds BBOX        WGS84 bounding box  -180,-85.0511,180,85.0511\n   -z ZOOM, --min-zoom ZOOM      Min zoom (inclusive)  0\n   -Z ZOOM, --max-zoom ZOOM      Max zoom (inclusive)  22\n   -r MODULE, --require MODULE   Require a specific tilelive module\n   -s SCHEME, --scheme SCHEME    Copy scheme  scanline\n   -i FILE, --info FILE          TileJSON copy data between tilelive providers\n{% endhighlight %} So let's go to execute the command to copy data from our MbS style to the local  folder. We want to generate tiles from zoom level 7 to 9 and indicating a bounding box wrapping Catalonia. Remember the  options must be indicated as . {% highlight bash %} ./node_modules/tl/bin/tl.js copy -z 7 -Z 9 -b \"0.023293972 40.4104003077 3.6146087646 42.9542303723\" tmstyle://./customstyle.tm2/ file://./tiles\nSegmentation fault: 11\n{% endhighlight %} Ough !!! That hurts, a segmentation fault. After looking for a while I realised it seems a bug. To solve it go to  and remove the  folder dependency. It is redundant because there is one installed in parent folder. Execute the command again and see the output:  The tl tool has created a local tiles directory and generated all the raster tiles for the given zoom levels and bounding box.Â The output shows in addition the time required to generate each tile. That's all. Now we only need to host the tiles at our own servers !!!"}},{"node":{"id":"4ce61f35-2426-51a1-8540-02b8592c47f3","frontmatter":{"title":"From SublimeText to Atom text editor","date":"2015-07-15 23:23"},"fields":{"slug":"/blog/2015/07/15/from-sublimetext-to-atom-text-editor","readingTime":{"text":"2 min read"}},"excerpt":"I have used regularly SublimeTextÂ (v2)Â for the past year. I used it mainly to programming in JavaScript, HTML, CSS and to write in Markdown syntax (I'm sorry but to programming in Java NetBeans continues to be my preferred IDE). In that time I used a bunch of SublimeText plugins to help me in my day to day: Markdown Editing. Provides a decent Markdown color scheme (light and dark) with more robust syntax highlighting and useful Markdown editing features. Markdown Preview.Â Preview and build your markdown files quickly in your web browser. Markdown TOC. Search headings in document and insert/update TOC(Table Of Contents) to it. DocBlockr. Simplifies writing DocBlock comments in many languages, one of them JavaScript. To the previous list we need to attach the spellchecker,Â autocomplete, minimap, highlight selected text and some more greatÂ core features of SublimeText.  A week ago I start using Atom text editor (v1.0.2) so I looked for a list of similar plugins that helps me in my day to day in the same way as previous plugins on SublimeText: Minimap,Â A preview of the full source code. Replicates the minimap core feature of SublimeText. Highlight Selected:Â Double click on a word to highlight it throughout the open file. Replicated the highlight selected text core feature of SublimeText. Markdown TOC:Â Generate/updates TOC (table of contents) of headlines from parsed markdown file. DocBlockr: Designed to make writing documentation faster and easier. We need to note by default atom.io has support for markdown syntax, autocompletion and spellchecker too."}},{"node":{"id":"1da3bea9-4d70-5104-9b51-b1ef2be6bf69","frontmatter":{"title":"The mystery of no flash session variables in Express + Passport auth","date":"2015-03-30 21:09"},"fields":{"slug":"/blog/2015/03/30/the-mystery-of-no-flash-session-variables-in-express-passport-auth","readingTime":{"text":"5 min read"}},"excerpt":"Recently I started an application using NodeJS with ExpressJS framework and decided to use passport for authenticate the users. As many other times I wanted to use flash messages so, when user authentication fails, the application shows a message informing about bad credentials.Â Nothing new on the horizon until.... OMG !!! I can't see the flash messages !!! Disclaimer: This is a really stupid history with me as starring. I like to learn from my errors and because of this I decide to write this post both as a punishment and to ensure I don't forget it again. The crime scene I was working implementing a sign up process, where the user writes its credentials and system createsÂ as a new user or returns an error message like \"Sorry, but a username with that email exists\" or similar. BeforeÂ introduce any code, the flow is as follows: User access the  page via GET method. Data is sent to  resource via POST method, which is responsible to: Check if data is fine, create a new user and redirected to the  page. If a user with the same email exists we redirect again to the  page (that is, using the GET method) with a flash message related to bad credentials. Note: A flash message is a variable stored within a session that is only available once, for the next request. That is if we put a flash variable and renders a page, the flash variable is available but if we render the same (or other) page again the flash variable is not present (it is destroyed). The approximate code for the previousÂ flow is as follows. First, the next code is responsible to receive the post data and register the user: {% highlight javascript %}\n// process the signup form\nrouter.post('/signup', passport.authenticate('local-signup', {\n  successRedirect : '/profile', // redirect to the secure profile section\n  failureRedirect : '/signup', // redirect back to the signup page if there is an error\n  failureFlash : true // allow flash messages\n})); The authentication is delegated to passport, which is implemented as:"}},{"node":{"id":"65d36648-c2ce-52e2-a00f-286813fee597","frontmatter":{"title":"Reading/writing compressed and not compressed files in Java","date":"2015-01-03 07:58"},"fields":{"slug":"/blog/2015/01/03/readingwriting-compressed-and-not-compressed-files-in-java","readingTime":{"text":"3 min read"}},"excerpt":"Main reason for this post is trying don't repeat yourself (DRY) because, often, I fall in the recursive need to read and write compressed and not compressed files (mainly JSON and CSV). Let's to see first how to read text files. Note I'm working with (relatively small) text files so: The read methods returns an String with the whole content. I'm usingÂ  to read line by line. {% highlight java %}\nprivate String readFile(String fileName) {\n    StringBuilder sb = new StringBuilder();\n    try {\n        BufferedReader input = new BufferedReader(new FileReader(new File(fileName)));\n        try {\n            String line = null;\n            while ((line = input.readLine()) != null) {\n                sb.append(line);\n            }\n        } finally {\n            input.close();\n        }\n    } catch (IOException ex) {\n        // Handle exception\n        return null;\n    } }\n{% endhighlight %} Note: there are more than one way to do things. InÂ the entry Best way to read a text file, where you can find many different ways to read a text file depending on your JDK version and the size of the file. Similarly to write a String to a file: {% highlight java %}\nprivate void writeFile(String fileName, String value) {\n    try {\n        FileWriter fw = new FileWriter(fileName);\n        BufferedWriter bw = new BufferedWriter(fw);\n        bw.write(value);\n        bw.close();\n    } catch (IOException ex) {\n        // Handle exception\n    }\n}\n{% endhighlight %} To read/write compressed files, that is with binary data, we need to work with streams and buffers. So to read a GZIP compressed file and obtain a String: {% highlight java %}\nprivate String readCompressedFile(String fileName) {\n    try {\n        GZIPInputStream gis = new GZIPInputStream(new FileInputStream(fileName));\n        ByteArrayOutputStream fos = new ByteArrayOutputStream();\n        byte[] buffer = new byte1024;\n        int len;\n        while ((len = gis.read(buffer)) != -1) {\n            fos.write(buffer, 0, len);\n        }\n        fos.close();\n        gis.close();\n        return new String(fos.toByteArray());\n    } catch (IOException ex) {\n        // Handle exception\n        return null;\n    }\n}\n{% endhighlight %} and similarly to write a String to a GZip compressed file: {% highlight java %}\nprivate void writeCompressedFile(String fileName, String value) {\n    try {\n        InputStream is = new ByteArrayInputStream(value.getBytes());\n        GZIPOutputStream gzipOS = new GZIPOutputStream(new FileOutputStream(fileName));\n        byte[] buffer = new byte1024;\n        int len;\n        while ((len = is.read(buffer)) != -1) {\n            gzipOS.write(buffer, 0, len);\n        }\n        gzipOS.close();\n        is.close();\n    } catch (IOException ex) {\n        // Handle exception\n    }\n}\n{% endhighlight %} References Next you can find a couple of great links with Java code for various JDK versions: Reading and writing text files Reading and writing binary files"}},{"node":{"id":"d235cc0e-11c8-5d32-9a97-690111a52542","frontmatter":{"title":"Why OpenLayers3 does not render my GeoJSON?","date":"2014-12-30 23:10"},"fields":{"slug":"/blog/2014/12/30/why-openlayers3-does-not-render-my-geojson","readingTime":{"text":"2 min read"}},"excerpt":"OpenLayers3 offers the  class that allows to read data from a GeoJSON source (an URL, a JavaScript object or a text string). Maybe you, like me, has spent some time trying to understand why your GeoJSON data is not rendering properly: projection is fine, your GeoJSON is well formed and validated but OpenLayers3 doesn't return any features and so nothing is rendered in the map. What is the problem? The  class is a subclass of  that uses an  instance to read content: A source class, by definition, acts as a source of features for a vector layers, that is, it is like a container of features. Because of this, the  source is limited to read GeoJSON features and not geometries. So next GeoJSON will be ignored by OpenLayers3 (really if you use de debug version you will see an assertion message): {% highlight javascript %}\n{\n    \"type\": \"Point\",\n    \"coordinates\": \n        -105.01621,\n        39.57422\n    \n}\n{% endhighlight %} While the next is a valid GeoJSON suitable to be read by the source: {% highlight javascript %}\n{\n    \"type\": \"Feature\",\n    \"geometry\": {\n        \"type\": \"Point\",\n        \"coordinates\": \n            -105.01621,\n            39.57422\n        \n    },\n    \"properties\": {\n        \"name\": \"Some feature property\"\n    }\n}\n{% endhighlight %} Â That means we can't read GeoJSON geometries? Absolutely no, simply means source classes follows the source concept, and that means, work with features. The  format class allows to read and write features and geometries. To read a GeoJSON file composed of geometries we need to read the geometries and, manually, create a feature for each one. For example: {% highlight javascript %}\nvar point = {\n    \"type\": \"Point\",\n    \"coordinates\": \n        -105.01621,\n        39.57422\n    \n}; // Read the GeoJSON geometries using the format class\nvar format = new ol.format.GeoJSON();\nvar geometry = format.readGeometry(point); // Create a feature using the geometry\nvar feature = new ol.Feature({\n  geometry: geometry,\n  propA: 'Some feature property'\n}); // Add feature to the source of some vector layer\nvectorLayer.getSource().addFeature(feature);\n{% endhighlight %}"}},{"node":{"id":"18333145-ba3a-50dc-acab-d903bd43340a","frontmatter":{"title":"How the JavaScript heatmap implementation works?","date":"2014-12-23 21:29"},"fields":{"slug":"/blog/2014/12/23/how-the-javascript-heatmap-implementation-works","readingTime":{"text":"2 min read"}},"excerpt":"A heatmap is a powerful way to visualise data. Given a matrix of data each value is represented by a color.Â The implementation of the heatmap algorithm is expensive in computation terms: for each grid's pixel you need to compute its colour from a set of known values. As you can thing, it is notÂ feasible to be implement it on the client side because map rendering wouldÂ be really slow.  But OpenLayers3 comes with a handy class, , which allows to render vector data as a heatmap, so the question is: how it is made? Really, the  layer uses a smart approximation to the algorithm which produces great results and is really fast. The steps can be summarised as: A gradient of colors is created as a 1x256 pixel size image. Each known value is rendered in a canvas as a grey blurred point using some radius. This produces a canvas where the blurred points can overlap each other and create more obscure zones. Something similar to this.  Finally, an image is obtained from the canvas and for each pixels a color is assigned. The color is obtained from the previous 1x256 pixel image obtained the color specified by the grey value (which goes from 0..255). The coloured image is then rendered in the map canvas, obtaining a nice effect suited to be used for density maps. The  offers some properties we can use to play better: , , ,  and . This last can be configured per feature, allowing to assign a level of importance to each feature determining in more or less measure the final color."}},{"node":{"id":"62c4e4b3-64b4-5a40-95d6-99b2e06d6211","frontmatter":{"title":"The Book of OpenLayers 3, completed !!!","date":"2014-12-16 19:50"},"fields":{"slug":"/blog/2014/12/16/the-book-of-openlayers-3-completed","readingTime":{"text":"1 min read"}},"excerpt":"It was a long road but finally it comes true: The Book of OpenLayers 3 is finished.  The chapter Controls and InteractionsÂ concludes the exploration of the main concepts related with OpenLayers version 3. This chapter is focused on showing how to work with the two main tools necessary to interact with the maps and its contents. New samples have been created. Remember the source code can be found at https://github.com/acanimal/thebookofopenlayers3 and a running demo is available at http://www.acuriousanimal.com/thebookofopenlayers3/. I must admit finished is not the best word to apply, OpenLayers3 is big, complex and awesome enough to write tons of chapters, but I must put a final dot and leave the typewriter... for a while :) Some of you have contact to me notifying spelling errors. I have given priority to the release of the final chapter. Please don't hesitate to contact me to notify me more error (or anything), my next release will be a maintenance version fixing all that errors. Many of you has suggested me many ideas on features to write about, so I think I will come back with a \"There is more\" really final chapter some day. Thanks for your confidence."}},{"node":{"id":"a83d7310-2157-570a-97bf-9b0ba2dcfb65","frontmatter":{"title":"Things to know when writing a book","date":"2014-11-15 12:25"},"fields":{"slug":"/blog/2014/11/15/things-to-know-when-writing-a-book","readingTime":{"text":"2 min read"}},"excerpt":"From my short experience, let me summarize some things you must take into account when writing a book. Its is not a mechanical process, it is more related with inspiration, but we must be constant and productive. Everyday is not the best day to write It is a fact, a law of universe. You could desire write but some days your brain is not clear enough, agile enough, fresh enough to write as you like. Don't force yourself. Don't hate yourself to be unable to write as you would like. Relax. Disconnect. Put your head in another tasks. Do some sport. The best thing to do when today isn't the best day to write is not to write. Markdown notation is great Yes, markdown syntax is great. It is simple, clear and powerful. At the beginning, if you come from a complex word processor like Word, Pages, LibreOffice or similar, you feel nude, but later you will appreciate that nudity. Markdown separates your raw writes from the final visualisation. A text editor is enough People tend to drown looking for the perfect tool to make the work. My advice is don't bother you, a simple text editor is enough to write any kind of book (otherwise askÂ to the hundreds of people that have written using a typewriter). Personally, I prefer a simple text editor over a word processor, because the first isolates the content from the way to visualise it. Of course technology can improve the way we work. We have tons of text editor, classics like vimÂ or emacsÂ text editors, the new onesÂ like SublimeText,Â TextMateÂ or the Ulysses application, and also, many online text editors, like dillinger.ioÂ or StackEdit. Keep cross references organized Some kind of books, like technical books, are plenty of cross references pointing to other sections, chapters or samples.Â It is vital for the author to maintain these references updated and organized. When using markdown a tend to organize the book as follows: Each chapter in a separate file namedÂ  Put a reference on each chapter title like:  Put a reference on each section title as  These simple tips help you organize the whole book references and simplifying the process to create cross references."}},{"node":{"id":"45cb9408-4876-5649-b2cb-c1428ed166fb","frontmatter":{"title":"New Overlays chapter on The Book of OpenLayers3","date":"2014-11-02 10:22"},"fields":{"slug":"/blog/2014/11/02/new-overlays-chapter-on-the-book-of-openlayers3","readingTime":{"text":"1 min read"}},"excerpt":"The Book of OpenLayers 3 has been updated !!! This book is self-published, no great editorial is behind it neither a marketing campaign, so I appreciate any shares you can make through social networks and any other media. What you can find in this new update? A new OverlaysÂ chapter. This is a short but necessary chapter that explains how we can work with overlays to place any kind of HTML located within the map. As I comment, it is a short chapter but I prefer to leave it as an independent chapter. A new sample on the Events, listeners and propertiesÂ chapter, named Styling features under the pointer. Once we know about feature styling and events, the sample demonstrates how we can change the style of the features under the pointer. The book has now 6 chapters and is 80% complete.Â Currently I continue working on a more extensive chapter called Controls and Interactions, which I hope to have finished in approximately a month. Please, don't hesitate to contact me with comments and suggestions. Your feedback is really valuable for me. Thanks for your confidence inÂ The Book of OpenLayers 3."}},{"node":{"id":"c6d94e9d-6d28-5130-89d9-a71da98ed2f4","frontmatter":{"title":"7 reasons to use Yeoman's angular-fullstack generator","date":"2014-10-18 12:17"},"fields":{"slug":"/blog/2014/10/18/7-reasons-to-use-yeomans-angular-fullstack-generator","readingTime":{"text":"3 min read"}},"excerpt":"For my next project and, after looking for candidates and reading some hundreds of lines of documentation, I finally choose to work with the so called MEAN stack: mongodb, express, angular and node. As with any other technology ecosystem, the great number of frameworks, libraries and tools can make our choiceÂ a challenge, and JavaScript is not an exception. But for JavaScript projects we have lot of help and I decide to use the awesome Yeoman tool. Yeoman combines the power of grunt, bower, npm and adds its own salt: the generators. Yeoman generators are tasks responsible to build the initial project scaffolding. Yeoman offers an extensive set of official generators oriented to create: webapps, backbone app, chrome extension, etc but we can also found a myriad of non official generators (yes, because anyone can create a new generator to satisfy his/her needs). Within all the generators I chose angular-fullstack to create my MEAN project structure and next are my reasons: 1. Easy to install You require to have node andÂ npmÂ installed on your system. Once you have them installYeomanÂ and theÂ angular-fullstackÂ is as easy as: Once installed the generator you simply need to create a new folder and initialise your project: {% highlight bash %} mkdir my-new-project && cd $_\nyo angular-fullstack app-name\n{% endhighlight %} 2. Creates both client and server scaffoldings The generator generates theÂ full stackÂ of your project, both the client and server code. Your project will start well organised and prepared to create an awesome RIA application. 3. Introduces good practices in the generated code Because the generated is made by experienced developers, theyÂ applies good practices in code organisation and style programming (like the environment configuration on the server side using node). For me, this is one of the most important reasons to use this generator. Anybody knows starting with a new technology is always hard, but it is nothing when you start with four new technologies :) 4. Server side API prepared to use authentication Following best practices the code is prepared so you can easily add security to you API via a node middleware so each request requires authentication of the client side. 5. Support HTML or jade templating on client side You can use any template engine for client side but by default the generator works with HTML and Jade. I don't really like Jade too much so I always try to use EJS or similar (Warning this last sentence is the author's opinion). 6. Support for different CSS preprocessors For different opinions there are different alternatives. This wayÂ angular-fullstackÂ has support for plain CSS, Stylus, SassÂ or LESSÂ pre-processors. Choose your preferred. 7. Commands to scaffold anything With theangular-fullstackÂ you can createÂ new end points for the server side or client side components (like routes, controllers, services, filters, directives, ...) with a sentences. So, next command: {% highlight bash %} yo angular-fullstack:endpoint message\n? What will the url of your endpoint to be? /api/messages\n{% endhighlight %} will produce: {% highlight bash %}\nserver/api/message/index.js\nserver/api/message/message.spec.js\nserver/api/message/message.controller.js\nserver/api/message/message.model.js  (optional)\nserver/api/message/message.socket.js (optional)\n{% endhighlight %} Â Conclusion In my opinion,Â angular-fullstackÂ is a really powerful tool that simplifies our day to day work. As always it is not the panacea, it is simply a generic tool to automatize many common tasks. Because of this we can found situations it lacks some feature."}},{"node":{"id":"181d8a9a-f393-596e-8131-44c64dc28a94","frontmatter":{"title":"The Book of OpenLayers 3, released !!!","date":"2014-10-08 19:31"},"fields":{"slug":"/blog/2014/10/08/the-book-of-openlayers-3-released","readingTime":{"text":"2 min read"}},"excerpt":"Finally I completed most of the chapters I had thought for the book. Although two chapters remains to be written, I think the current content is extensive enough to help anybody interested to lean this great new version of the OpenLayers project. The current chapters explains: The map and the view Layers Data sources and formats Vector layers Events, listeners and properties The two remaining chapters I have in mind are: Controls and interaction Overlays  Hope, this book help you to introduce to the OpenLayers version 3. Remember, thanks to the LeanPub platform, when you buy the book you can get any later update I make on it. In addition, you have 45 days for refund if you think the book does not cover your expectations. In addition, don't hesitate to contact me for any errors, misspelled words or sentences, etc. Remember, this is a self-published book. No main company is behind it and no great marketing campaign is prepared. Any help from you, talking about the book at any forum or social network will be appreciated. Finally, I would like to thankÂ my wife, Pilar, for her understanding and almost infinite patience forÂ my job, hobby and profession, the computer science."}},{"node":{"id":"8a7b25cd-536c-5e18-b71a-1da1b3956044","frontmatter":{"title":"Announcing the release of The Book of OpenLayers 3","date":"2014-09-23 17:33"},"fields":{"slug":"/blog/2014/09/23/announcing-the-release-of-the-book-of-openlayers-3","readingTime":{"text":"2 min read"}},"excerpt":"I just sent this words to all the people interested in the book via LeanPub and I would like to post it here too, hoping this message arrives to more people. The Book of OpenLayers3 is progressing well. It is not finished but I would like to notify you, in the next weeks, I will launch a pre-release of the book. At this moment the book contains five chapters covering the most important topics of the new architecture and design of the library. All chapters are divided in a theory section, where I explain all the concepts and involved classes, and a practice section, where I show real working examples. Remember, all the examples are also freely available at the GitHub repository: https://github.com/acanimal/thebookofopenlayers3 are right now running at: http://www.acuriousanimal.com/thebookofopenlayers3. My intention is continue writing, at least, two more chapters. One dedicated to the controls OpenLayers3 offers to interact with the map, and a second one, related to the concept of overlays. I hope to cover these two chapter in one month. Thanks to LeanPub platform, once you buy a book you are allowed to download the new updates freely. I will notify you when new releases are available. Please, do not hesitate to send me your feedback related with the book, from its content to its costs. Finally, remember this book is self published, no great publishing company is behind it and no great marketing campaigns are organised, so any comments on shared networks that publicise the book will be appreciated. Antonio Santiago (@acanimal) - #thebookofopenlayers3"}},{"node":{"id":"35aae226-2ad1-5415-bbf6-f7deea3a3f4c","frontmatter":{"title":"Releasing code samples for The Book of OpenLayers 3","date":"2014-08-22 23:05"},"fields":{"slug":"/blog/2014/08/22/releasing-code-samples-for-the-book-of-openlayers-3","readingTime":{"text":"2 min read"}},"excerpt":"Writing a book is hard, requires constance and motivation and, more important, be strong to keep them both. Least but not last you need time. Time to see the source code and learn. Time to see the examples and learn. Time to understand all the concepts and learn. Time to explain in your words what you have learnt. Today, I announced the links where you can find the online samples and code repository for The book of OpenLayers3. Code repository is open, so don't hesitate to download and contribute with new samples. The work is not complete, I need to finish the theory part of a chapter relatedÂ to vector information and write two more chapters I have in mind and, of course, create some samples to see the theory in practice. I will write another post introducing the book with a more in depth chapter description. This post is only about the code samples. Your feedback is really valuable for me !!!  About the code samples For those interested in contribute, the project for the code samples is built using the Yeoman tool, which combines Grunt and Bower,Â and the generator for web application , which offers a project skeleton with a bunch of good practices. In addition to the default plugins used by the generator, I made use of the Grunt's pluginÂ  (see here) that implement like PHP include directive. This way, I can create a page layout (with headers, footers, etc) reusable for all the pages. See the  file for more details about plugins. For the implementation I made use of the Bootstrap framework, the nice Yeti theme from Bootswatch project and the highlight.js project to highlight the samples code. See more details of project dependencies in the  file."}},{"node":{"id":"5f4e5a9b-082d-5af8-a927-9b1c29e37df7","frontmatter":{"title":"Leaflet and how avoid map panning on mouseout","date":"2014-05-12 08:31"},"fields":{"slug":"/blog/2014/05/12/leaflet-and-how-avoid-map-panning-on-mouseout","readingTime":{"text":"3 min read"}},"excerpt":"A couple of days ago\n, a friendÂ asked this simple question in a Spanish forum. The scenario is simple, you have a map and when dragging it you would like to stop the action when the mouse goes beyond the limits ofÂ the map, really beyond the  (or any other DOM element that) contains the map. The first try anyone can try could be something like: {% highlight javascript %}\n// create a map in the \"map\" div, set the view to a given place and zoom\nvar map = L.map('map').setView(51.505, -0.09, 13); // add an OpenStreetMap tile layer\nL.tileLayer('http://{s}.tile.osm.org/{z}/{x}/{y}.png', {\n    attribution: 'Â© OpenStreetMap contributors'\n}).addTo(map); // Register event to enable/disable dragging on mouse out.\nmap.on('mouseout', function() {\n    map.dragging.disable();\n});\nmap.on('mouseover', function() {\n    map.dragging.enable();\n});\n{% endhighlight %} but that has no effect. (See here) Now, remove the  listener and try again: {% highlight javascript %}\n// create a map and add the layer\nvar map = ... // Register event to enable/disable dragging on mouse out.\nmap.on('mouseout', function() {\n    map.dragging.disable();\n});\n{% endhighlight %} surprisingly, when the mouse goes out the map the dragging action continues active and once you finish dragging the  method seems to take place and you can't drag the map again. (See here). After some time looking at Leaflet source code (we aware I have done it for Leaflet 0.7.2) I found a possible solution but, first, let me do some explanation. The  class has attached hooks, like drag, or zoom actions, which provides the map with some behavior. TheÂ  class is responsible to control the dragging action. It has / methods and, more important, it uses internally aÂ  instance, which is responsible to detect and catch mouse events on the map. This way: theÂ Â catches mouse events onÂ Â the map panel (also for mouse move), makes some process and triggers some new events that are catch by theÂ Â instance theÂ Â instance makes some process and triggers the know map events  and . In addition, invoking  implies a call to  too but (I don't understand yet why), it seems not takes effect until you release the mouse button. TheÂ Â instance continues catching mouse event and informingÂ  All this say, a possible solution to stop the dragging action when the mouse goes out the map panel is to freeze the work ofÂ  Please, note the next code violates almost all the SOLID(http://en.wikipedia.org/wiki/SOLID_(object-oriented_design) principles, so don't fire me. {% highlight javascript %}\nL.Draggable.prototype.freeze=false;\nL.Draggable.prototype.updatePosition= function () {\n    if(this._freeze) {\n        return;\n    } };\n{% endhighlight %} The code adds a new  property to theÂ  class and redefines the  method to check the property. Now, you can freeze the mouse dragging action as: {% highlight javascript %}\nmap.on('mouseout', function() {\n    map.dragging.draggable.freeze=true;\n});\nmap.on('mouseover', function() {\n    map.dragging.draggable.freeze=false;\n});\n{% endhighlight %} You can see it in action here."}},{"node":{"id":"15d558df-cf8c-5581-b6d3-b2eefa5a9470","frontmatter":{"title":"The book of OpenLayers3 is coming !!!","date":"2014-02-15 15:55"},"fields":{"slug":"/blog/2014/02/15/the-book-of-openlayers3-is-comming","readingTime":{"text":"1 min read"}},"excerpt":"This week the beta2 version of OpenLayers3 has been released (see the OpenLayers3 is comming from Boundlessgeo blog) with great improvements on vector layers rendering and image manipulation. Similarly, The book of OpenLayers3 follows a similar progress, always one or two steps after the project evolution. Currently, you can found a sample chapter about the Map and View, both theory and practice, and I have almost finished the next chapter focused on how to work withÂ Layers. After explaining layers the natural flow is explain the Sources and Formats, which allows to load content from a great number of data sources. They are very related to layers, but I preferred to differentiate the concepts in two separated chapters. This is what I'm currently working on. What else requires to be in the book? I need to make a chapter focused on vector data, explain how to work with geometries, features and styles. Events are also important, we can listen for changes in objects and react accordingly. As you can see there are many work to be done yet and your feedback is the most valuable thing I can get at this moment."}},{"node":{"id":"8ea54c29-5d31-5d8e-9437-c9ee48021c76","frontmatter":{"title":"Randomatic, to generate random sequences","date":"2014-01-27 20:39"},"fields":{"slug":"/blog/2014/01/27/randomatic-to-generate-random-sequences","readingTime":{"text":"1 min read"}},"excerpt":"This is my own implementation of a tool to generate random character sequences:Â RanomaticÂ !!! Why is it useful for? Really not much, simply helps me generate random password. Allow uppercase, lowercase letters, numbers and other non ASCII characters Easy to use Mobile ready  Source code: https://github.com/acanimal/Randomatic\nDemo: http://www.acuriousanimal.com/Randomatic/"}},{"node":{"id":"4248face-948e-543c-9430-f5e0f94b4d38","frontmatter":{"title":"Sample chapter for The book of OpenLayers3 is out !!!","date":"2014-01-25 12:08"},"fields":{"slug":"/blog/2014/01/25/sample-chapter-for-the-book-of-openlayers3-is-out","readingTime":{"text":"1 min read"}},"excerpt":"A couple of days ago I release the sample chapter for The book of OpenLayers3. I will appreciate all your feedback, comments, ideas, ... The chapter is dedicated to two of the main concepts within the OpenLayers3, the map and the view. While in previous versions the map was the central piece that controls from layers or controls to the way the map is visualized, that is, the extension and projection to be used, in OpenLayers3 these responsibilities has been decouples. The map continues being responsible to contain layers, controls or (the new) overlays, but there is a new concept, the view, responsible to determine how the map is visualize. So the view is who determines the visible map extent, center location or projection. Take into account OpenLayers3 is in active development so things can vary slightly until the final release of OpenLayers3 and this book. Help me promoting the book and remember I'm waiting for your comments."}},{"node":{"id":"df625f78-e8a9-54a4-898b-c9ae12f3bad0","frontmatter":{"title":"SublimeText plugins for writing a book in markdown","date":"2014-01-09 19:48"},"fields":{"slug":"/blog/2014/01/09/sublimetext-plugins-for-writing-a-book-in-markdown","readingTime":{"text":"2 min read"}},"excerpt":"I'm currently involved on writing The book of OpenLayers3 using the great LeanPub platform.\n  LeanPub has many benefits (I should write a post some day talking about) and one of them are you write the book using the markdown notation (really a slightly extended dialect) and they generate automatically your book in PDF, ePub and mobi formats."}},{"node":{"id":"7a33fbad-be04-5476-9add-c07344a45c5f","frontmatter":{"title":"Feedback for The book of OpenLayers3","date":"2014-01-02 12:44"},"fields":{"slug":"/blog/2014/01/02/feedback-for-the-book-of-openlayers3","readingTime":{"text":"1 min read"}},"excerpt":"Finally I have decided to use LeanPub as the platform to publish my book. Here you can see the public page with a description about it: The book of OpenLayers3. Hope within a couple of weeks I can publish a sample chapter."}},{"node":{"id":"fe985108-91ee-5390-9cf8-b3f1f3706ccc","frontmatter":{"title":"Professional purposes for the new year 2014","date":"2013-12-30 12:51"},"fields":{"slug":"/blog/2013/12/30/professional-purposes-for-the-new-year-2014","readingTime":{"text":"2 min read"}},"excerpt":"With the arrival of each new year everybody has new great purposes and new goals to achieve. I'm not talking from the personal point of view but the professional too: practice more sport, to quit smoke, read some book, learn a new programming language, ..."}},{"node":{"id":"a33ee7e8-9932-5720-9abc-dbec7182a551","frontmatter":{"title":"The book of OpenLayers3","date":"2013-12-24 17:31"},"fields":{"slug":"/blog/2013/12/24/the-book-of-openlayers3","readingTime":{"text":"2 min read"}},"excerpt":"I was thinking on it for a long time, but due a lack of free time I never started. Finally I can officially say I have start writing The book of OpenLayers3."}},{"node":{"id":"c39afe7a-0a1b-5d2f-b191-3739ae07222b","frontmatter":{"title":"Using more than one property file in Spring MVC","date":"2013-12-10 22:27"},"fields":{"slug":"/blog/2013/12/10/using-more-than-one-property-file-in-spring-mvc","readingTime":{"text":"2 min read"}},"excerpt":"Spring is one of the most important, powerful and also complex frameworks in the actual Java panorama."}},{"node":{"id":"f0e36493-4162-5335-a603-d031929c92fe","frontmatter":{"title":"Symfony2, Doctrine, FOSUserBundle and fixtures for functional testing","date":"2013-10-17 22:21"},"fields":{"slug":"/blog/2013/10/17/symfony2-doctrine-fosuserbundle-and-fixtures-for-functional-testing","readingTime":{"text":"2 min read"}},"excerpt":"I have an application built with Symfony2 framework which uses the Doctrine2 ORM for persistence.\nThe issue is I need to make functional tests\nallowing to purge and initialize the database with doctrine fixtures. class MyFixtures implements FixtureInterface, ContainerAwareInterface { }"}},{"node":{"id":"37b7826b-f72c-5c1d-830e-017936f9e2d7","frontmatter":{"title":"A visual exploration of the Nobel Prize history","date":"2013-08-15 20:19"},"fields":{"slug":"/blog/2013/08/15/a-visual-exploration-of-the-nobel-prize-history","readingTime":{"text":"3 min read"}},"excerpt":"After some time in mind, finally I have got some free time to spend creating a web page to show the information related to Nobel Prizes."}},{"node":{"id":"55370dc4-4ce2-5195-949f-951a0f1c2c41","frontmatter":{"title":"The OpenLayers fallen and Leaflet arise... sure???","date":"2013-05-05 18:59"},"fields":{"slug":"/blog/2013/05/05/the-problem-with-openlayers","readingTime":{"text":"5 min read"}},"excerpt":"I wrote this post some months ago, before I publish the OpenLayers Cookbook, but I never published it thinking it could start a flame war instead a constructive thread."}},{"node":{"id":"a39f5f61-d8e6-5fd8-acba-03853e190c65","frontmatter":{"title":"SimplyWrite, a free web distraction writing tool","date":"2013-04-29 21:26"},"fields":{"slug":"/blog/2013/04/29/simplywrite-a-free-web-distraction-writing-tool","readingTime":{"text":"2 min read"}},"excerpt":"I like to write and I like programming so the obvious consequence were to write some tool to write.Â More or less this is the history of SimplyWrite."}},{"node":{"id":"b9d9efe1-6f0c-5300-be3c-24e01f2f91db","frontmatter":{"title":"The Book: GeoServer Beginner's Guide","date":"2013-04-01 15:25"},"fields":{"slug":"/blog/2013/04/01/the-book-geoserver-beginners-guide","readingTime":{"text":"3 min read"}},"excerpt":"GeoServer is one of the most importants open source geospatial servers nowadays. Implemented in Java, based on the powerful GeoTools libraries, GeoServer offers a great degree of interporability publishing data from major spatial data sources using Open Geospatial Consortium (OGC) standards."}},{"node":{"id":"3218d37a-d9a6-5482-b073-1cc1fd180dec","frontmatter":{"title":"Things I learned creating a jQuery Plugin (Part II)","date":"2013-02-25 22:22"},"fields":{"slug":"/blog/2013/02/25/things-i-learned-creating-a-jquery-plugin-part-ii","readingTime":{"text":"6 min read"}},"excerpt":"This post is the continuation of the seriesÂ Things I learned creating a jQuery Plugin. } } }; }"}},{"node":{"id":"552bc6fe-11b0-5a16-99a6-054f4f8bd25f","frontmatter":{"title":"AnimatedCluster pan related bug... fixed !!!","date":"2013-02-08 18:59"},"fields":{"slug":"/blog/2013/02/08/animatedcluster-pan-related-bug-fixed","readingTime":{"text":"1 min read"}},"excerpt":"If you regularlyÂ follow this blog and are web mapping developer that works with OpenLayers, (too much coincidences???) probably you know about theÂ theÂ Animated marker cluster strategy for OpenLayersÂ I created some time ago."}},{"node":{"id":"89433524-fbb9-56bf-9193-b14f3fc8cf2c","frontmatter":{"title":"Things I learnt creating a jQuery Plugin (Part I)","date":"2013-01-15 23:31"},"fields":{"slug":"/blog/2013/01/15/things-i-learned-creating-a-jquery-plugin-part-i","readingTime":{"text":"8 min read"}},"excerpt":"jQuery is one of the most used JavaScript libraries, if not the most used one, which allows to make great things with the big set of little tools it offers to the web developers: HTML/DOM manipulation, CSS manipulation, HTML event methods, effects and animations, AJAX, utilities, ... }; };"}},{"node":{"id":"5a69614c-0862-55be-b9ed-eefb6aa7ab28","frontmatter":{"title":"OpenLayers, create a checkboard layer to know the tile names using Google Charts API","date":"2013-01-11 12:02"},"fields":{"slug":"/blog/2013/01/11/openlayers-create-a-checkboard-layer-to-know-the-tile-names-using-google-charts-api","readingTime":{"text":"2 min read"}},"excerpt":"Pyramid tiles are used by many providers as a more efficient way (than WMS server) to provide images. The idea is simple, we have zoom levels and on every level we have NxN tiles of a specific size (typically 256x256 pixels). Google, Yahoo, Bing or OpenStreetMaps are samples of tile providers. }); });"}},{"node":{"id":"9a9d2ce9-29e0-5c7e-b7d7-7d983dbc1d2c","frontmatter":{"title":"OpenLayers, how compute the tile \"name\" under the mouse","date":"2013-01-01 11:53"},"fields":{"slug":"/blog/2013/01/01/openlayers-how-compute-the-tile-name-under-the-mouse","readingTime":{"text":"1 min read"}},"excerpt":"I have working on a web page using OpenLayers which among others shows aÂ \n  OpenStreetMapÂ layer.\n  The issue is I need to move the mouse over the map and print on a label the tileÂ nameÂ \n  in the form ofÂ z/x/y, for example,Â 5/15/10. });"}},{"node":{"id":"9255753b-4f50-56c9-be75-6cd634a1e206","frontmatter":{"title":"tagger, a jQuery Plugin to manage tags","date":"2012-12-26 18:51"},"fields":{"slug":"/blog/2012/12/26/tagger-a-jquery-plugin-to-manage-tags","readingTime":{"text":"2 min read"}},"excerpt":"jQuery is widely used in the web world. Since its creation it was quickly adopted by many programmers mainly due its easily of us and extension capabilities."}},{"node":{"id":"2ebe19b4-f5ed-5815-9f9a-35814ab6bec8","frontmatter":{"title":"OpenLayers presentation and OpenLayers Cookbook examples code update","date":"2012-12-04 21:29"},"fields":{"slug":"/blog/2012/12/04/openlayers-presentation-and-openlayers-cookbook-sample-code-update","readingTime":{"text":"3 min read"}},"excerpt":"A few months after the release of the OpenLayers Cookbook I have been working on a presentation about OpenLayers for @geoinquiets at Barcelona (BCN) that will be celebrated the next DecemberÂ 20th (see the event here) at the offices of Cantera-Tech."}},{"node":{"id":"91327705-588e-5aa7-880c-41289cb19487","frontmatter":{"title":"Projections, projections, projections","date":"2012-10-24 19:55"},"fields":{"slug":"/blog/2012/10/24/projections-projections-projections","readingTime":{"text":"1 min read"}},"excerpt":"Create a map of the earth isn't an easy problem. Projections basically tries to solve the problem of how to 3D element on a 2D surface. Tons of papers have beenÂ writtenÂ about this problem but a nice place to start is the wikipedia entry about Map Projections."}},{"node":{"id":"8ba286fc-56a8-5d3c-a430-90299b0863ec","frontmatter":{"title":"Things seen last week","date":"2012-10-19 18:01"},"fields":{"slug":"/blog/2012/10/19/things-seen-this-october-2012","readingTime":{"text":"2 min read"}},"excerpt":""}},{"node":{"id":"b51354c0-b351-5367-ad6b-87b5657b346e","frontmatter":{"title":"Improved performance on the AnimatedCluster for OpenLayers","date":"2012-10-09 23:42"},"fields":{"slug":"/blog/2012/10/09/improved-performance-on-the-animatedcluster-for-openlayers","readingTime":{"text":"2 min read"}},"excerpt":"Yes, now I'm really proud to present the AnimatedCluster strategy for OpenLayers. Some time ago I created an AnimatedCluster strategy for OpenLayers that extends the basic Cluster strategy,\n  animating cluster when user changes the zoom. {% highlight javascript %}\nfor(var i=0; i<this.features.length; ++i) {\n    feature = this.featuresi; }\n{% endhighlight %}"}},{"node":{"id":"4370f819-bccf-526a-bc2f-ceb91feb3f69","frontmatter":{"title":"OpenLayers Cookbook pirated... but you can continue buying it !!!","date":"2012-09-27 22:40"},"fields":{"slug":"/blog/2012/09/27/openlayers-cookbook-pirated-but-you-can-continue-buying-it","readingTime":{"text":"1 min read"}},"excerpt":"Approximately a month ago my book OpenLayers Cookbook was released by PacktPublishingÂ and today I found it is available at many sites of debatable reputation. Really I'm surprising by the velocity of this alternative publication process :)"}},{"node":{"id":"0a73901e-8a43-561c-b7a7-79826319a322","frontmatter":{"title":"Architexa product review","date":"2012-09-23 15:30"},"fields":{"slug":"/blog/2012/09/23/review-of-architexa-product","readingTime":{"text":"4 min read"}},"excerpt":"Architexa product is an Eclipse plugin from Architexa.comÂ company. As their web site say:"}},{"node":{"id":"ebf6bf8f-5780-5ce4-a6ba-8d02618dc2af","frontmatter":{"title":"Creating static maps in OpenLayers using PhantomJS","date":"2012-09-17 17:30"},"fields":{"slug":"/blog/2012/09/17/creating-static-maps-in-openlayers-using-phantomjs","readingTime":{"text":"4 min read"}},"excerpt":"Many times in a web mapping application it is desired to save a picture with the current map information.Those who works with Google Maps API has also the <a href=\"https://developers.google.com/maps/documentation/staticmaps/\" Static Maps API, which works similarly than Google Maps but produces static images. if (system.args.length < 4 || system.args.length > 6) {\n    console.log('Usage: rasterize_element.js URL filename selector paperwidth*paperheight|paperformat zoom');\n    console.log('  paper (pdf output) examples: \"5in7.5in\", \"10cm20cm\", \"A4\", \"Letter\"');\n    phantom.exit(1);\n} else {\n    address = system.args1;\n    output = system.args2;\n    selector = system.args3;\n    page.viewportSize = { width: 600, height: 600 };\n    if (system.args.length > 3 && system.args2.substr(-4) === \".pdf\") {\n        size = system.args3.split('*');\n        page.paperSize = size.length === 2 ? { width: size0, height: size1, margin: '0px' }\n                                           : { format: system.args3, orientation: 'portrait', margin: '1cm' };\n    }\n    if (system.args.length > 4) {\n        page.zoomFactor = system.args4;\n    }\n\tconsole.log(\"Loading page...\");\n    page.open(address, function (status) {\n        if (status !== 'success') {\n            console.log('Unable to load the address!');\n        } else {\n            window.setTimeout(function () {\n                console.log(\"Getting element clipRect...\");\n                var clipRect = page.evaluate(function (s) {\n\t                var cr = document.querySelector(s).getBoundingClientRect();\n\t                return cr;\n                }, selector); }"}},{"node":{"id":"81ed5be5-ae1e-550c-876e-c8436eca08d4","frontmatter":{"title":"Taking web page screenshots","date":"2012-09-15 16:12"},"fields":{"slug":"/blog/2012/09/15/taking-web-page-screenshots","readingTime":{"text":"4 min read"}},"excerpt":"Recently I have worked on system that requires to take web page screenshots. Not only a screenshot of the whole page but of a concrete element. Looking on the net I have found many solutions for this problems, which can be classified in to categories: if (system.args.length < 3 || system.args.length > 5) {\n    console.log('Usage: rasterize.js URL filename paperwidth*paperheight|paperformat zoom');\n    console.log('  paper (pdf output) examples: \"5in7.5in\", \"10cm20cm\", \"A4\", \"Letter\"');\n    phantom.exit(1);\n} else {\n    address = system.args1;\n    output = system.args2;\n    page.viewportSize = { width: 600, height: 600 };\n    if (system.args.length > 3 && system.args2.substr(-4) === \".pdf\") {\n        size = system.args3.split('*');\n        page.paperSize = size.length === 2 ? { width: size0, height: size1, margin: '0px' }\n                                           : { format: system.args3, orientation: 'portrait', margin: '1cm' };\n    }\n    if (system.args.length > 4) {\n        page.zoomFactor = system.args4;\n    }\n    page.open(address, function (status) {\n        if (status !== 'success') {\n            console.log('Unable to load the address!');\n        } else {\n            window.setTimeout(function () {\n                page.render(output);\n                phantom.exit();\n            }, 200);\n        }\n    });\n}"}},{"node":{"id":"a0bb778c-9a32-5818-b1af-ff20daf85abe","frontmatter":{"title":"PhoneGap on iOS: an stupid advertisement using the \"create\" command line tool","date":"2012-09-11 16:20"},"fields":{"slug":"/blog/2012/09/11/phonegap-on-ios-an-stupid-advertisement-using-the-create-command-line-tool","readingTime":{"text":"2 min read"}},"excerpt":"Some days ago I start my first mobile application. Nothing awesome, it is a simply excuse to test jQuery Mobile and PhoneGap frameworks. This post is not oriented to describe my impressions, that would be another day, but describe an stupid headache I have when trying to install the PhoneGap framework in my MacOSX."}},{"node":{"id":"b5660d3e-112a-5552-ba8e-6693c98e1642","frontmatter":{"title":"AnimatedCluster demo site updated to work with OpenLayers 2.12","date":"2012-09-06 19:50"},"fields":{"slug":"/blog/2012/09/06/animatedcluster-demo-site-updated-to-work-with-openlayers-2-12","readingTime":{"text":"1 min read"}},"excerpt":"Not an awesome post but for any interested in the AnimatedCluster strategy I have updated the demo site to work properly with OpenLayers 2.12."}},{"node":{"id":"d406ea8f-bad8-5a4c-bfdc-ec3d7e9a588f","frontmatter":{"title":"OpenLayers Cookbook is out !!!","date":"2012-09-02 13:49"},"fields":{"slug":"/blog/2012/09/02/openlayers-cookbook-is-out","readingTime":{"text":"2 min read"}},"excerpt":"I'm proud to announce it. My first work as author of a technical book sees the light.Â After some months of work (really hard work combined with my day to day job), finally the book is out:"}},{"node":{"id":"df2a1cce-fcb2-5c54-b842-bab9c6bcbdb2","frontmatter":{"title":"Animated marker cluster strategy for OpenLayers","date":"2012-08-19 18:32"},"fields":{"slug":"/blog/2012/08/19/animated-marker-cluster-strategy-for-openlayers","readingTime":{"text":"10 min read"}},"excerpt":"Yes, this posts talks about my implementation of a cluster strategy that animates clusters when changing the zoom level. So, if you are one of those don't like to read the blog posts from others and like the action, you can go directly to see AnimatedCluster demoÂ page. or to the github repository to see the source code."}},{"node":{"id":"2a62fd67-360c-5681-b3cd-5e377fca9710","frontmatter":{"title":"Awesome clustered markers in Leaflet","date":"2012-08-12 10:14"},"fields":{"slug":"/blog/2012/08/12/awesome-clustered-markers-in-leaflet","readingTime":{"text":"3 min read"}},"excerpt":"Some time ago someone asked at gis.stackexchange.comÂ for nice cluster marker implementation, both for Leaflet or\n  OpenLayers, something similar\n  to Redfin.\n  A couple of weeks ago I discover a great implementation for Leaflet, the\n  Leaflet.markercluster from Dave Leaver."}},{"node":{"id":"8f0bd1c5-c73f-5c2f-be0e-0cbfb0cc6f63","frontmatter":{"title":"Look mom no jQuery !!! Getting all CSS properties of a DOM element in JavaScript","date":"2012-07-09 22:25"},"fields":{"slug":"/blog/2012/07/09/look-mom-no-jquery-getting-all-css-properties-of-a-dom-element-in-pure-javascript","readingTime":{"text":"2 min read"}},"excerpt":"Getting and setting CSS properties is a simple task. We can make it in pure JavaScript:"}},{"node":{"id":"f4fc77b1-9c7b-50e4-b6fa-7c7ff25687b5","frontmatter":{"title":"Brief introduction to Dojo Widgets creation","date":"2012-07-08 16:46"},"fields":{"slug":"/blog/2012/07/08/brief-introduction-to-dojo-widgets-creation","readingTime":{"text":"1 min read"}},"excerpt":"In the past, I have been using Dojo Toolkit for relatively little projects. I choose Dojo by its well designed API and its rich and homogeneous set of widgets.jQuery and jQueryUI are great projects, but I found the problem of consistency with jQuery plugins. Each one follow its own rules, each one has its documentation and API, etc."}},{"node":{"id":"92880a74-ec2f-5af3-bd8d-6a91945e4bc9","frontmatter":{"title":"OpenLayers Cookbook","date":"2012-06-28 22:09"},"fields":{"slug":"/blog/2012/06/28/openlayers-cookbook","readingTime":{"text":"2 min read"}},"excerpt":"I'm near to finish my first experience as the author of a technical book. Titled OpenLayers Cookbook it has been written for PacktPublishing editorial, while the OpenLayers version 2.11 was the stable release."}},{"node":{"id":"30b4dfa5-b674-54f7-b926-9ed4b4fcfe0b","frontmatter":{"title":"Jelastic, cloud platform for Java","date":"2012-06-23 21:03"},"fields":{"slug":"/blog/2012/06/23/jelastic-cloud-platform-for-java","readingTime":{"text":"5 min read"}},"excerpt":"Some days ago I receive an invitation for testing Jelastic\n  product and, today Saturday, I had a while, made my homework and had my first contact with the platform."}},{"node":{"id":"e6ff757a-450f-5c4d-89b6-09c0c98ce29b","frontmatter":{"title":"Stupid PHP snippet to always download a changing file","date":"2012-05-06 20:02"},"fields":{"slug":"/blog/2012/05/06/stupid-php-snippet-to-always-download-a-changing-file","readingTime":{"text":"1 min read"}},"excerpt":"It is short, it is easy, it is stupid but... can save you time. If you need to download every few minutes a remote file that changes its contents at regular intervals of time this is for you."}},{"node":{"id":"29d4b67a-9f76-5c2e-9eb1-8bd72aa03e8a","frontmatter":{"title":"The dojox.grid widgets family and the strange case of the items modification","date":"2012-04-28 21:52"},"fields":{"slug":"/blog/2012/04/28/the-dojox-grid-widgets-family-and-the-strange-case-of-the-items-modification","readingTime":{"text":"3 min read"}},"excerpt":"So, you are building a web application and decided to use the great Dojo framework. Â Probably, if you need to use grids, you will decide to use some of the available widgets subclass of dojox.grid. Well, my friend, be aware with the data you use to fill the grid's store !!! function(DataGrid, ItemFileWriteStore){ });"}},{"node":{"id":"07a321bb-30a2-5114-a079-a877b72b4a98","frontmatter":{"title":"What Doesn't Stay in Vegas?","date":"2012-03-13 08:15"},"fields":{"slug":"/blog/2012/03/13/what-doesnt-stay-in-vegas","readingTime":{"text":"1 min read"}},"excerpt":"Today, and thanks to a colleague, I found this great video about how the Las Vegas city has grown in the past years. When Landsat 5 launched on March 1, 1972, Las Vegas was a smaller city. This image series, done in honor of the satellite's 28th birthday, shows the desert city's massive growth spurt since 1972. The outward expansion of the city is shown in a false-color time lapse of data from all the Landsat satellites."}},{"node":{"id":"dfb93327-bbae-5ba8-bbe8-dde36a5e1be0","frontmatter":{"title":"Scale-adaptative Projection","date":"2012-03-08 21:09"},"fields":{"slug":"/blog/2012/03/08/scale-adaptative-projection","readingTime":{"text":"1 min read"}},"excerpt":"Take a look to this awesome exercise from the Oregon State University:"}},{"node":{"id":"17335b20-59e0-57bb-9e42-0bdb5aa63f60","frontmatter":{"title":"Dojo + OpenLayers = New Challenges","date":"2012-01-23 23:23"},"fields":{"slug":"/blog/2012/01/23/dojo-openlayers-new-challenges","readingTime":{"text":"8 min read"}},"excerpt":"Recently, the new Dojo 1.7 was released with many improvements and important changes.\nAs a developer, I'm pleased to work with Dojo on RIA application because simple reasons: </html> // Create a map instance\nvar map = new dojox.geo.openlayers.Map('map');\nmap.fitTo(-10,30,40,62); // Add to the GFX layer\ngfxLayer.addFeature(feature);\ngfxLayer.redraw(); };\nvar graphFeature1 = new dojox.geo.openlayers.WidgetFeature(descr1);\ngfxLayer.addFeature(graphFeature1); };\nvar graphFeature2 = new dojox.geo.openlayers.WidgetFeature(descr2);\ngfxLayer.addFeature(graphFeature2);"}},{"node":{"id":"ff5c4c5b-ba82-526b-9014-6ad990a75ce0","frontmatter":{"title":"Presentation tools in the browser","date":"2012-01-05 15:35"},"fields":{"slug":"/blog/2012/01/05/presentation-tools-in-the-browser","readingTime":{"text":"2 min read"}},"excerpt":"With the arrival of HTML5+CSS3 the browsers are getting more attention because the new possibilities. One example of the possibilities are the proliferation of frameworks, tools and libraries to create HTML presentations to run in the browser. No need to transform your presentation from PowerPoint or Keynote to any portable format, the content is plain HTML."}},{"node":{"id":"8269136f-eb81-58f5-b02a-ac5ebbabc4c9","frontmatter":{"title":"Filling Flexigrid with JSON/XML data","date":"2011-12-09 22:14"},"fields":{"slug":"/blog/2011/12/09/filling-flexigrid-with-jsonxml-data","readingTime":{"text":"1 min read"}},"excerpt":"Flexigrid is one of the most useful and powerful grid plugins for jQuery. Unfortunately, as the author explains in the project page, there is no much documentation so you must learn how to use it looking at existing code. If anytime you need to fill a Flexigrid with JSON or XML content and you are a little buggy to look at example code, here is the great summary:"}},{"node":{"id":"702174dc-9864-5580-8d41-e2a4249331e3","frontmatter":{"title":"Greedy and Nongreedy Matching in a Regular Expression","date":"2011-11-19 00:11"},"fields":{"slug":"/blog/2011/11/19/greedy-and-nongreedy-matching-in-a-regular-expression","readingTime":{"text":"1 min read"}},"excerpt":"This questions has come to me many times so it is time to write a post that acts as a reminder."}},{"node":{"id":"835d7b9c-2897-5671-a9b4-a6cc9c07e626","frontmatter":{"title":"Open alternatives to Google Maps","date":"2011-11-14 20:43"},"fields":{"slug":"/blog/2011/11/14/open-alternaties-to-google-maps","readingTime":{"text":"4 min read"}},"excerpt":"Lately there was a not much surprising news about Google products and services. Among other things Google has changed the Google Maps API use policy and will charge to those users that exceed some download limits."}},{"node":{"id":"9f37a1dd-d193-545d-900c-36695ccdcc90","frontmatter":{"title":"Using YouTube API to embed videos dinamically on your web site","date":"2011-11-02 22:22"},"fields":{"slug":"/blog/2011/11/02/using-youtube-api-to-embed-videos-on-your-web-site","readingTime":{"text":"5 min read"}},"excerpt":"It is easy to embed a given YouTube video on a web site, simply use the wizard to get code required code, but what about to do the some automatically using JavaScript? Yes, suppose you have a preferred user you follow all his videos and would like to put his/her latest video in your web site."}},{"node":{"id":"0c0abe91-8d89-502b-929f-d30a9d5ef81f","frontmatter":{"title":"Sending emails with Java","date":"2011-10-08 13:41"},"fields":{"slug":"/blog/2011/10/08/sending-emails-with-java","readingTime":{"text":"5 min read"}},"excerpt":"Update: This article is a bit outdated ðŸ˜… You can find a nice read at the blog post Guide to Send Emails in Java from the mailtrap.io team. I start writing this post as a simple \"how to send an email\" using Java, but later I found I need to briefly explain more things. So, here is this kind of all in one summary about sending emails with Java. Outside the Java SE platform, but included in JavaEE one, the JavaMail package provides a platform to build mail and messaging applications. Lets go with an example. Sending a simple text message Alternatively, instead using: you can use next to set the message content: Multipart messages That's fine, but usually you don't send simple text messages. Instead you send nice HTML body messages with bold or italic text, images, and so on. NOTE: See below at references section to see about MIME format which extends the data you can attach to an email to allow multiparts, attachments, etc. When you write a multipart message the content is composed of different parts, for example one part is the message written as simple text and a second part with the same message written in an enhanced way using HTML. Then the client that reads the message is responsible to render the appropriate part depending on its capabilities. Â  Sending attachments Terrific, we know how to send a plain text email and something more incredible like a multipart message with HTML content. Next step is to send an email attaching too some files. Create an email with attached file is similar to create a multipart message where one part can be the text of the message and another part is the attached file. The secret is in the next lines: Â  HTML messages Create a message o multipart message with HTML content is really easy, simply specify the MIME type in the setContent method: The idea is as follow: first you need to attach the image file and set an identifier and second you need to write your HTML code and reference the image identifier in the 'img' tag. Anything more to say? Arrived to this point you are almost a master of sending emails. You know how to send simple emails, multipart emails with richest HTML content and attach files and images on your message. What more can a programmer desire? Probably, a more easy to use API and that is what Apache Commons Email project offer you. See the 'user guide' section http://commons.apache.org/email/userguide.html to understand what I say. It offers a more abstract API more close to humans than to protocols. References JavaMail - JavaMail project home page. Apache Commons Email - Apache Commons subproject to simplify the way to work with JavaMail API. See the 'user guide' section http://commons.apache.org/email/userguide.html. MIME (Multipurpose Internet Mail Extensions) - Description of MIME format for multipart emails."}},{"node":{"id":"d7ed0529-ce20-5f91-a49e-60c16c4da1f7","frontmatter":{"title":"Clinker, a software development ecosystem","date":"2011-09-27 20:48"},"fields":{"slug":"/blog/2011/09/27/clinker-an-software-development-ecosystem","readingTime":{"text":"1 min read"}},"excerpt":"Recently I discovered Clinker, a so called Software Development Ecosystem. Mysteriously there is no definition for Development Ecosystem on Wikipedia yet but a close definition could be:"}},{"node":{"id":"dc0f4fa7-71cf-541a-8a05-54600bb1ef00","frontmatter":{"title":"Crop image on the client side with JCrop and HTML5 canvas element","date":"2011-09-26 15:29"},"fields":{"slug":"/blog/2011/09/26/crop-image-on-the-client-side-with-jcrop-and-html5-canvas-element","readingTime":{"text":"2 min read"}},"excerpt":"Suppose you are working on a nice web application where the user can upload images to, for example, a shop catalogue (mmm... that makes me think on something :p ) but wait... you don't the catalogue uses the whole image you upload instead a piece of it. So, we need to crop the image. function updatePreview(c) {\n\tif(parseInt(c.w) > 0) {\n\t\t// Show image preview\n\t\tvar imageObj = $(\"#target\")0;\n\t\tvar canvas = $(\"#preview\")0;\n\t\tvar context = canvas.getContext(\"2d\");\n\t\tcontext.drawImage(imageObj, c.x, c.y, c.w, c.h, 0, 0, canvas.width, canvas.height);\n\t}\n};"}},{"node":{"id":"c3db2cfd-0b9a-5ff8-a48f-e73d5d21f4fd","frontmatter":{"title":"A word about LESS","date":"2011-08-29 08:32"},"fields":{"slug":"/blog/2011/08/29/a-word-about-less","readingTime":{"text":"2 min read"}},"excerpt":"Woow!!! That is the word that best defines Less."}},{"node":{"id":"c17db88e-4592-5854-8cbe-4b03fa5c0308","frontmatter":{"title":"Customizing jQuery UI Dialog: hiding close button and changing opacity","date":"2011-08-16 14:02"},"fields":{"slug":"/blog/2011/08/16/customizing-jquery-ui-dialog-hiding-close-button-and-changing-opacity","readingTime":{"text":"2 min read"}},"excerpt":"Sometimes when you are programming small things are the hard things, little details becomes difficult to solve and you need to spend lot of time to solve them. This is logically :) because you spent the major part of your time thinking and designing the big or complex things, leaving in a second plane the small things and because this they became the new \"big\" things. Ok, stop talking with buggy sentences and talk about this post. Recently I was working in a web page using jQuery UI dialogs that have a couple of special requirements that takes me some time and because this I want to share here with you:"}},{"node":{"id":"95dfa619-2002-5d05-a0ff-02ae5364447c","frontmatter":{"title":"Local storage: Storing sticky notes on your machine with HTML5","date":"2011-08-12 11:00"},"fields":{"slug":"/blog/2011/08/12/local-storage-storing-sticky-notes-on-your-machine-with-html5","readingTime":{"text":"3 min read"}},"excerpt":"Every history has a beginning and for this post it starts when some time ago I saw this good post from tutorialzine.com. Really I love the tutorials at tutorialzine.com, they are great quality examples to learn."}},{"node":{"id":"c430d45e-d8fb-5050-a019-09786488ca15","frontmatter":{"title":"A geek joke","date":"2011-07-29 15:12"},"fields":{"slug":"/blog/2011/07/29/a-geek-joke","readingTime":{"text":"1 min read"}},"excerpt":"It makes me smile: A man walks into a Doctorâ€™s and says â€œDoctor, I think Iâ€™m addicted to Twitter.â€ Doctor looks at him and says â€œSorry, I donâ€™t follow you.â€"}},{"node":{"id":"0f748ce2-ca9c-5050-98df-c0bdff929ede","frontmatter":{"title":"Generating map tiles without a map server. GeoTools the GIS swissknife.","date":"2011-07-23 22:14"},"fields":{"slug":"/blog/2011/07/23/generating-map-tiles-without-a-map-server-geotools-the-gis-swissknife","readingTime":{"text":"6 min read"}},"excerpt":"Recently I was playing with latest version of GeoServer. It includes the GeoWebCache, something which can improve your server performance greatly. GeoServer solves and helps lots of problems to work and visualize geospatial data but as you know map servers lakes from scalability. // Get lightning store\nDataStore dataStore = DataStoreFinder.getDataStore(params);\nSimpleFeatureSource sfs = dataStore.getFeatureSource(\"lightnings\"); // Style for Positivos\nGraphic grP = styleFactory.createDefaultGraphic();\nMark markP = styleFactory.getCircleMark();\nmarkP.setStroke(styleFactory.createStroke(filterFactory.literal(Color.BLUE), filterFactory.literal(1)));\nmarkP.setFill(styleFactory.createFill(filterFactory.literal(Color.CYAN)));\ngrP.graphicalSymbols().clear();\ngrP.graphicalSymbols().add(markP);\ngrP.setSize(filterFactory.literal(5)); // Style for Negativos\nGraphic grN = styleFactory.createDefaultGraphic();\nMark markN = styleFactory.getCircleMark();\nmarkN.setStroke(styleFactory.createStroke(filterFactory.literal(Color.RED), filterFactory.literal(1)));\nmarkN.setFill(styleFactory.createFill(filterFactory.literal(Color.ORANGE)));\ngrN.graphicalSymbols().clear();\ngrN.graphicalSymbols().add(markN);\ngrN.setSize(filterFactory.literal(5)); Filter filterPositiveValor = ff.and(filter, CQL.toFilter(\"value >= 0\"));\nFilter filterNegativeValor = ff.and(filter, CQL.toFilter(\"value < 0\")); // Create symbols and rules to render every feature\nPointSymbolizer symPositivos = styleFactory.createPointSymbolizer(grP, null);\nPointSymbolizer symNegativos = styleFactory.createPointSymbolizer(grN, null); Rule ruleP = styleFactory.createRule();\nruleP.symbolizers().add(symPositivos);\nruleP.setFilter(filterPositiveValor);\nFeatureTypeStyle ftsP = styleFactory.createFeatureTypeStyle(new Rule[]{ruleP}); Rule ruleN = styleFactory.createRule();\nruleN.symbolizers().add(symNegativos);\nruleN.setFilter(filterNegativeValor);\nFeatureTypeStyle ftsN = styleFactory.createFeatureTypeStyle(new Rule[]{ruleN}); // Finally create out style\nStyle style = styleFactory.createStyle();\nstyle.featureTypeStyles().add(ftsP);\nstyle.featureTypeStyles().add(ftsN); }"}},{"node":{"id":"c4d5b359-af7b-5d80-9dd3-4e63bad80966","frontmatter":{"title":"A heatmaps layer for OpenLayers","date":"2011-06-09 19:20"},"fields":{"slug":"/blog/2011/06/09/a-heatmaps-layer-for-openlayers","readingTime":{"text":"3 min read"}},"excerpt":"As I commented on a previous post I know about heatmaps.js project some time ago and interest me a lot by its possibilities with OpenLayers. Of course it is not the only solution, see here and here but it has a great performance."}},{"node":{"id":"6635f57d-1ec1-5847-a33a-9fa5b5cce91e","frontmatter":{"title":"Heatmaps in OpenLayers","date":"2011-06-06 07:30"},"fields":{"slug":"/blog/2011/06/06/heatmaps-in-openlayers","readingTime":{"text":"2 min read"}},"excerpt":"Some month ago I found nice post on how to create heatmaps using HTML5 canvas element. Its author, Patrick Wied, created a nice JavaScript code responsible to create a heatmap over an image depending on the mouse click or mouse move events."}},{"node":{"id":"7a8c2d09-b12c-5d65-9932-84ed076cd586","frontmatter":{"title":"XCode4 and the mystery with Route-Me code sense","date":"2011-05-06T15:08:59.000Z"},"fields":{"slug":"/blog/2011/05/06/xcode4-and-the-mystery-with-route-me-code-sense","readingTime":{"text":"2 min read"}},"excerpt":"If you follow this blog you will know I prefer to write \"long\" posts with nice content :) form time to time than write lots of short posts without much substance. For that I use Twitter :p"}},{"node":{"id":"2fa803b7-efe4-5cc5-bf26-ebe0a0fd9c13","frontmatter":{"title":"SimplyWrite, a free web distraction writing tool based on IndexedDB","date":"2011-04-17 19:26"},"fields":{"slug":"/blog/2011/04/17/simplywrite-a-free-web-distraction-writing-tool-based-on-indexeddb","readingTime":{"text":"5 min read"}},"excerpt":"SimplyWrite is a free web distraction writing tool. It is based in the IndexedDB HTML5 so you need a browser compliant. Because the use of IndexedDB all the content is stored locally on your machine, no data is transferred or stored in a remote server. };\nwriteRequest.onsuccess = function ( e ) {\n};"}},{"node":{"id":"138b57c0-3680-51d2-8f11-ef6879c4e489","frontmatter":{"title":"acanimal is using github to share code !!!","date":"2011-04-15 18:33"},"fields":{"slug":"/blog/2011/04/15/acanimal-is-using-github-to-share-code","readingTime":{"text":"1 min read"}},"excerpt":"After some time as a pending task, finally I have Â created a github account to share code and any other things with you."}},{"node":{"id":"ba0d2988-091d-5bb7-bf92-b4801c7507d7","frontmatter":{"title":"How to Create a Cross-Platform Application with NASA WorldWind & NetBeans Platform","date":"2011-03-10 22:46"},"fields":{"slug":"/blog/2011/03/10/how-to-create-a-cross-platform-application-with-nasa-worldwind-netbeans-platform","readingTime":{"text":"4 min read"}},"excerpt":"This post is a mini tutorial on how to create an application based on NetBeans Platform that uses the WorldWind Java virtual globe. Before to continue, you need to have some knowledge about NetBeans Platform, WWJ and JOGL. setLayout(new BorderLayout());\nadd(wwj, BorderLayout.CENTER);"}},{"node":{"id":"d1a98a09-0ee5-5ce9-a0dd-2cd9c8dd75e3","frontmatter":{"title":"Downloading files from AEMET FTP server with Java and Apache Commons Net","date":"2011-03-06 19:57"},"fields":{"slug":"/blog/2011/03/06/downloading-files-from-aemet-ftp-server-with-java-and-apache-commons-net","readingTime":{"text":"8 min read"}},"excerpt":"Some time ago the AEMET, the Spanish governmentÂ meteorological agency, release many of its data publicly: weather radar, weather stations, lightnings, ...  The way they do is simple andÂ effective:Â public the contents on a FTP server and update on regular intervals of time.  Talking with a colleague we decide to create (on our very few free time) a simple web page that allows people to see the current values of the weather stations. A map of Spain with some dots representing weather stations and a graph with showing data from the selected station. Update: This service was stopped in 2012 by Spanish government ðŸ˜” File localFolderObservacions = new File(localFolder, \"observaciones_diezminutales\");\nlocalFolderObservacions.mkdir(); } // Connect to server\nftpclient.connect(server);\nftpclient.setFileTransferMode(FTPClient.BINARYFILETYPE); // Loggin\nif (!ftpclient.login(\"anonymous\", null)) {\n    logger.severe(\"Can't log into FTP\");\n    return;\n}\n// Change directory\nif (!ftpclient.changeWorkingDirectory(folder)) {\n    logger.log(Level.SEVERE, \"Can''t change to folder ''{0}''.\", folder);\n    return;\n}\n// Change to day directory\nString remoteDayFolder = Utils.getStringFromDate(this.date) + \"_diezminutales\";\nif (!ftpclient.changeWorkingDirectory(remoteDayFolder)) {\n    logger.log(Level.SEVERE, \"Can''t change to day folder ''{0}''.\", remoteDayFolder);\n    return;\n} } fos = new FileOutputStream(localfile);\nftpclient.retrieveFile(ftpfile.getName(), fos); logger.log(Level.INFO, \"Downloaded finished at ''{0}'' , size:''{1} ''bytes , timestamp: ''{2}''.\",\n        new Object[]{Utils.getCurrentFormattedDate(), ftpfile.getSize(), ftpfile.getTimestamp().getTime()}); // Uncompress file\nString targetName = localfile.getName().replaceAll(\".gz\", \"\");\nFile targetlocalfile = new File(localfile.getParentFile(), targetName);\nif (Utils.uncompressGzFile(localfile, targetlocalfile)) {\n    //\n    // TODO - Here you can handle the file.\n} else {\n    // If there is any error uncompressing file then remove files to\n    // ensure it will be downloaded again.\n    localfile.delete();\n    targetlocalfile.delete();\n}"}},{"node":{"id":"295f94d7-f384-591c-99d1-67d06659c3c5","frontmatter":{"title":"notemarklet: Transform selected element into a sticky note","date":"2011-02-09 22:59"},"fields":{"slug":"/blog/2011/02/09/notemarklet-transform-selected-element-into-a-sticky-note","readingTime":{"text":"3 min read"}},"excerpt":"Bookmarklets are nothing new but I never created one. There are tons of available bookmarklets to make tons of useful little things but here is my little but nice bookmarklet :) called notemarklet that helps reading marking the element under the mouse and changing its looks as a sticky note. Next there are a couple of samples: })();"}},{"node":{"id":"83bc84b2-67c3-5b8d-9d48-6b446bdfc0db","frontmatter":{"title":"Working with the JavaScript XMLHttpRequest object","date":"2011-01-27 23:07"},"fields":{"slug":"/blog/2011/01/27/working-with-the-javascript-xmlhttprequest-object","readingTime":{"text":"7 min read"}},"excerpt":"In the last years JavaScript has become one of the most important programming languages. Probably one of the most famous words related to JavaScript is AJAX (Asynchronous JavaScript and XML).  Request from JavaScript are made through the XmlHttpRequest JavaScript object which lets you open connections, send the request and handle data returned by the server.  This post is about XMLHttpRequest object, how to use it and how to handle data in a synchronous or asynchronous way. function createXHRObject() {\n\tvar xhrobject = null;\n\tfor ( var i = 0; i < XMLHttpFactories.length; i++) {\n\t\ttry {\n\t\t\txhrobject = XMLHttpFactoriesi;\n\t\t} catch (e) {\n\t\t\tcontinue;\n\t\t}\n\t\tbreak;\n\t}\n\treturn xhrobject;\n}; var req = createXHRObject();"}},{"node":{"id":"67c4b9c0-53ee-5661-a9d0-016d62c759cb","frontmatter":{"title":"JavaScript animations (tweening): Why maths are important?","date":"2010-12-18 19:50"},"fields":{"slug":"/blog/2010/12/18/javascript-animations-why-maths-are-important","readingTime":{"text":"7 min read"}},"excerpt":"In a previous post I show how to make a simple scrolling animation using jQuery. jQuery library has lots of effects, many more added in jQuery UI and much more as plugins.Â Of course it is fine to use existing libraries to not reinvent the wheel, but there are times you need to do an animation by your hand without the help of existing libraries and because this one needs to know the basics to implement JavaScript animations.Â Right, so how we can make animations in JavaScript and how we can make it smooth? Let's go. } } }"}},{"node":{"id":"43d4a5e4-4c10-58e4-92b0-161daa7e7692","frontmatter":{"title":"How to create a preloader in Dojo","date":"2010-12-05 11:22"},"fields":{"slug":"/blog/2010/12/05/how-to-create-a-preloader-in-dojo","readingTime":{"text":"5 min read"}},"excerpt":"Dojo is a great framework to create RIA applications. Dojo isn't only a bunch of utility functions to select DOM nodes, change styles, make some effects, etc in contrast it is a whole framework with a great set of UI widgets. };"}},{"node":{"id":"5467e9d5-42b9-5d7a-987e-2acac2a53249","frontmatter":{"title":"Animated scrolling to a DOM element","date":"2010-11-23 20:05"},"fields":{"slug":"/blog/2010/11/23/animated-scrolling-to-dom-element","readingTime":{"text":"2 min read"}},"excerpt":"Creating my web page I have wanted to create a smooth movement to a given page element, for example from top to about section. One possibility, of course, is to code it yourself, but we are lucky to have tons of JavaScript libraries and frameworks to help us on that tasks. On of them areÂ jQuery, one of the most used libraries."}}]}},"pageContext":{"isCreatedByStatefulCreatePages":true}}}