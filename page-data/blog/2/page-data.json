{"componentChunkName":"component---src-templates-blog-list-js","path":"/blog/2","webpackCompilationHash":"4776e6576de27e274acc","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"e7437c42-3111-5c2f-8e4c-14bc0aa5e986","frontmatter":{"title":"Understanding the NodeJS cluster module","date":"12 August, 2017","layout":"post"},"fields":{"slug":"/blog/2017/08/12/understanding-the-nodejs-cluster-module/","readingTime":{"text":"8 min read"}},"excerpt":"NodeJS processes runs on a single process, which means it does not take advantage from multi-core systems by default. If you have an 8 core CPU and run a  NodeJS program via  it will run in a single process, wasting the rest of CPUs. Hopefully for us NodeJS offers the cluster module that contains a set of functions and properties that help us to create programs that uses all the CPUs. Not a surprise the mechanism the cluster module uses to maximize the CPU usage was via forking processes, similar to the old fork() system call Unix systems."}},{"node":{"id":"6c6ecf9c-985e-5267-bcbc-f1a3d5ec46bf","frontmatter":{"title":"fetch API and Express sessions","date":"11 December, 2016","layout":"post"},"fields":{"slug":"/blog/2016/12/11/fetch-api-and-express-sessions/","readingTime":{"text":"4 min read"}},"excerpt":"TL;DR fetch API is the successor of XHR and although it's really powerful ( see What is the difference between the Fetch API and XMLHttpRequest?) you should take care of some things, like the fact you are responsible to determine if cookies must be sent to the server."}},{"node":{"id":"3f1ef8dc-7d9b-5590-89ef-98db4252f12d","frontmatter":{"title":"Configuring Atom editor with ESLint and the AirBnB style guide rules","date":"14 August, 2016","layout":"post"},"fields":{"slug":"/blog/2016/08/14/configuring-atom-with-eslint/","readingTime":{"text":"5 min read"}},"excerpt":"TL;DR This article demonstrate how to integrate the ESLint tool with Atom editor so our source code be automatically checked, showing linting messages in editor. In addition, ESLint will be configured based on the AirBnB code style rules. Atom & ESLint Atom editor is probably one of the most used text editors (along with SublimeText, Visual Studio Code, TextMate, ...). On his side, ESLint is an open source project, originally created by Nicholas C. Zakas, with the goal to provide a pluggable linting utility for JavaScript. Usually, the way to use ESLint involves the command line, invoking it to check our project's code at some point (for example, before made a build) or automatizing its execution with a tool like Gulp or Grunt each time a file is modified. ESLint also accepts a configuration files, like , where we can define the set of rules we want the tool checks. The issue is, as you can imagine, the number of rules ESLint accepts is really huge. The importance of a style guide In projects with many developers it can be useful define a set of rules that force all of them to code with the same style, that is, use a style guide. The problem with style guides is they are set of good practices-conventions that everybody assumes the rest are applying. As you can image working with assumptions in a big and shared code is not good. Without a tool like ESLint there must be people acting as a police, that is, spending time reviewing the code style and not only the code. Thanks to ESLint this time can be reduced forcing each member of the team to ensure the code follows the same convention rules before committing or pushing to the repository. Besides, using CI tools (like GitHub with TravisCI) we can also check the code style and disable the possibility to merge a branch if the code lint fails. The AirBnB JavaScript Style Guide Creating and maintaining a style guide is not an easy tasks. Hopefully, the awesome people at AirBnB have created the AirBnB JavaScript Style Guide for us that I have chose because of: Works with ES5 and ES6: arrow functions, object destructuring, array spread, ... Includes React and JSX style: one component per file, recognizes stateless vs class component, ... It is based on ESLint. I want to note here the Standard JS project, which defines a set of rules ready to be used in our JS projects. Related with what I have said in the previous section, I want to highlight two sentences written in the main page of the project: This module saves you (and others!) time in two ways: No configuration. The easiest way to enforce consistent style in your project. Just drop it in. Catch style errors before they're submitted in PRs. Saves precious code review time by eliminating back-and-forth between maintainer and contributor. Integrating ESLint with Atom Ok, enough talk and lets start working. We need to make two things: first, configure ESLint in our project (for this we also need to install the AirBnB style guide), and second install necessary Atom plugins to show messages while coding. Configuring ESLint in your project The first thing we need to do is configure ESLint in our project. Remember we are going to use the AirBnB style guide so we need no install the required package and make our ESLint configuration extend from the AirBnB ESLint configuration. Install ESLint locally to your project: . Install the AirBnB ESLint configuration. Following package instructions we need to execute next sentences to install the right package versions and dependencies: Create a  file in the root of our project. We must be sure to include the property  as part of the configuration. Next is a sample configuration file. Note we inherited configuration from AirBnB. In addition, we have added the eslint rules  and  to forces us to write some JSDoc for functions, methods and classes. Right now our project is configured with ESLint and the base set of rules from AirBnB, but it requires we execute ESLint manually or automatize in some way (in the build process). Installing Atom plugins Lets go to configure Atom to automatically lint files and show us message while coding. Be sure you have completed successfully the previous sections. Install the Atom plugin linter-eslint. You are finished :) The plugin will detect automatically the  file in your project and will start linting on the fly the source code showing all the errors and warning.  Conclusions ESLint is a powerful tool that help teams ensuring quality code. On his side Atom is become a great and powerful editor, mainly due the active community and the growing set of plugins. The combination of both tools can improve greatly our productivity so, no doubt and try it !!!"}},{"node":{"id":"f9fdb2de-bab8-586a-aaae-eb7048e2a0e7","frontmatter":{"title":"Introducing Universal Web Applications","date":"10 August, 2016","layout":"post"},"fields":{"slug":"/blog/2016/08/10/universal-applications/","readingTime":{"text":"8 min read"}},"excerpt":"TL;DR: This post is the first in a series of articles to talk about Universal (previously known as Isomorphic) Web Applications. The goal of the series is to describe: What an universal web application is? Why are them important? What benefits offers universal web apps? and How to create a boilerplate to start a universal app project. Note, because JavaScript ecosystem is incredible bast and, because we can create an universal web app with almost any combination of framework and libraries, we will use in this series React, Redux and Webpack."}},{"node":{"id":"b8825777-cb02-533e-afe0-1c1dfa228489","frontmatter":{"title":"Resilient PHP applications with Phystrix","date":"06 July, 2016","layout":"post"},"fields":{"slug":"/blog/2016/07/26/resilient-php-applications-with-phystrix/","readingTime":{"text":"6 min read"}},"excerpt":"TL;DR: This post talks about how to make our PHP applications more resilient, that is, they must be able to adapt to third party failures and recover quickly from them. You will see why configuring timeouts is not enough to protect your system and what better tools exists. We will explain briefly Hystrix concepts and introduce an alternative for PHP called Phystrix. No matter how well designed be your system, no matter the number, kind or quality of your tests. There is only once thing for sure: your system will fail. Although we can well design, implement and test our systems we have dependencies with third party services: databases, queues, call REST API on another systems, ... In the decade of microservices where dependency/communication among systems becomes a main pilar we need mechanisms to make our systems resistant among third party failures. We need to resilience, that is, recover quickly from disasters. The problem with dependencies In the best case you can be sure your system will work fine but you can make the same assumption for the third party systems you communicate with (another microservices, databases, queues, ...). So the problems arise when some third party services starts failing. This can be because of: The system is near collapse, your requests arrives but they take too much time to be replied. This means each request that arrives to our system is hold until the third party service responds. Because the third party system works slowly we start holding too much connections which could collapse our system too. In addition, although the third party system is near collapse we continue sending requests, so we are not helping to mitigate the problem, we are increasing it. Collapse of a third party service can collapse our system. The system is down. Many drivers tries to establish a connection during a given period of time before raising an exception. Why to wait for a connection if we know the system is down? The classic (and not the right) way to solve The classic way and, a good practice, to mitigate this problem is to configure the timeouts for each library and driver you use to communicate to every third party service. As example, Guzzle allows to set a  when instatiating a : Or the SncRedisBundle for Symfony allows to specify the timeout both for connection and read/write actions: As I said, setting timeouts is a good practice, but it not solves the problem. If the third party is down and we have a timeout of 2 seconds we guaranty our systems will finish the query in two seconds but, why send request and spend 2 seconds while we know the system is down? A robust solution As we talk at the beginning, the goal is to make our system resilient, that is, it must be able to adapt to third party failures and recover quickly from them. This means: Do not call a third party if we know it is down or takes too much time to respond. Fail quickly. If our system receives a request and we can't complete due lack of support from a third party service, we can fail quickly. The client, although it will receive a bad response, will receive a response quickly and our system should be able to attend a new request. You can see how this will avoid a cascade failure of our system. Hopefully, some years ago the Netflix engineers worked in a solution called Hystrix which is so good that has become one of the most famous tools when working with microservices in Java. Hystrix is a latency and fault tolerance library designed to isolate points of access to remote systems, services and 3rd party libraries, stop cascading failure and enable resilience in complex distributed systems where failure is inevitable. Hystrix implements the circuit breaker pattern. Following the electrical circuits analogy, each dependency of our system to a third party service can be seen as a cable with an interruptor. While the communications with the third party works fine, the interruptor is closed (allowing flow the electricity), but when a problem is detected in the third party system (i.e due a timeout) the interruptor is opened making our system impossible to communicate with the third party, which makes our system fail quickly when a dependency fails. A robust solution for PHP After looking some libraries I finally decide to use Phystrix, a Hystrix port to PHP made by oDesk (now Upwork). Following Hystrix design, Phyxtrix requires all the actions we want to make against a third party service (querying a database, inserting into a queue, etc) must be encapsulated as a command (see the command pattern). The library offers and abstract command class from we can inherit when creating our commands. It is up to us to implement the  method responsible to make the real action (the call to a service, the insert into database, etc) and optionally the  method that returns a result if the third party is not available. The good part is each time a command is executed, the base command class collects metrics (like the number of failed call to a third party) and is responsible to manage the circuit state (open or close) depending on the current metric values. Note Phystrix stores all the metric in APC, so you should have this extension enabled. Additionally, the people from oDesk implemented two more tools: phystrix-bundle: A bundle for Symfony2 that can help us integrate Phystrix into our Symfony projects. phystrix-dashboard: Some classes that helps creating an endpoint in our application to serve the metrics stores by Phystrix. This endpoint can be added to the hystrix-dashboard tool to monitor our metrics in almost real time. hystrix-dashboard Conclusions Our systems has dependencies to other systems we can't control. Setting timeouts in our connections is a good practice but it is not enough. Hystrix is a tool that implements the circuit breaker pattern, which can help our systems to be more resilient. Phystrix is a Hystrix port for PHP. It is easy to integrate in our PHP applications and protect against latency, fault tolerance and cascade failures when working with third party systems."}},{"node":{"id":"d290be60-47df-5c9d-807c-485640183f23","frontmatter":{"title":"Symfony, images and S3","date":"25 March, 2016","layout":"post"},"fields":{"slug":"/blog/2016/03/26/symfony-and-s3/","readingTime":{"text":"6 min read"}},"excerpt":"Paraphrasing the movie title Sex, lies and videotape, this post is related on how I configured my symfony project to work with images (including thumbnail generation) and store all them on Amazon S3 service. There are are libraries and bundles to work with images and also others to work with S3, but the combination of all them can be a tricky experience with not much documentation out there. In addition, there is also one more challenge to achieve and, that is, while developing I want to store images locally (in a directory) but when deployed I want to use S3 storage. Currently I'm working on a project where users can upload photos. The application allows users to create collections, drag and drop images, order them and finally upload to the server. In addition, the user can explore his/her collections, browse images and download collections in a single ZIP file. All this having in mind: While developing locally we want to store images in the local server folder. In staging or production environment we want to use S3. Original images must remain private, while the thumbnails must be public to be included in the application web pages. We need to generate thumbnails with different sizes. When a user access to a collection a list of small thumbnails are shown. When user clicks an image a medium thumbnail is presented. When user downloads a collection the ZIP file must include the original images. So, in summary, we need to deal with image upload, thumbnail generation and S3 service. Uploading images For image uploading we have used the VichUploaderBundle. Uploading images isn't a secret but can involve some extra tasks. The VichUploaderBundle helps working with file uploads that are attached to ORM entities, that is, it is responsible to move the images to some configured place and attach it to your entity. In addition, we want to store images in folders classified by user and collection, something like , where  and  are identifiers. A nice feature VichUploaderBundle offers is the possibility to attach the so called directory namer or file namer that determines the final name for the upload file. This way when a file is uploaded, given the current user and the selected collection, we determine dynamically the target folder where the bundle must store the image. Note the ORM entity only has the image file name. The path to the file is computed through the specified directory and/or file namers. For this reason, the bundle also includes the methods require to get the absolute path to a file given the file name stored within the entity. Generating thumbnails To generate thumbnails we have used the LiipImagineBundle bundle. With it, when you reference an image within your templates you don't get the original image but a new one obtained applying some filters. Next line shows how to include an image in your twig template obtained after applying a  configuration: The good thing is LiipImagineBundle generates the thumbnails when images are first time accessed and stores them in a cache folder for next calls. Abstracting the file system The issue is we want to upload images and generate thumbnails into a local folder at development time and to S3 when running in staging or production. Hopefully for us there is the Gaufrette bundle, which is an abstract filesystem. It offers a common interface to read/write to different filesystem and a bunch of implementations to work against the local filesystem, an FTP server, Amazon S3 service, ... and many more. Putting it all together Arrived here, the main question is how to configure the three bundles to work together, in summary: We want to abstract the filesystem to work locally while developing and with S3 in production. We need to upload images. We need to generate thumbnails for uploaded images and store them in a cache folder to be later server. We have divided the configuration between the  file and the . The first contains the configuration for the previous three bundles ready to work locally. The second overrides some propertires to work in production, using S3. The first point is to configure the Gaufrette bundle to abstract our filesystem. Next is the configuration in the : Compare with parameters we override in the . Note for production you need to define an AWS-S3 service which I do not include here. We define a  filesystem which by default uses a  adapter and in production uses an  one. Next step is to configure the VichUploaderBundle bundle. Hopefully it is designed to integrate with Gaufrette so it is easy to specify how to upload files through gaufrette. Next is the configuration: As you can see we are specifying we want to use gaufrette with  and the upload destination is the previous defined gaufrette filesystem . This means all images will be uploaded through the Gaufrette filesystem to that destination. Note, within the target filesystem, the final folder and file name are determined by a custom directory namer we have implemented ( which adds the user ID to the path) and the file namer  offered by Gaufrette, which assigns a unique name to each file. Finally, we need to configure the LiipImagineBundle bundle. Next is the configuration used for local development. We need to specify the cache folder where to generate the thumbnails in adition to our filter, that will generate with size  and half quality: Main properties to configure are the and the . The first one uses the stream  that uses gaufrette filesystem. The second uses the resolver  that we have configured to use the local folder . For production, configuration changes slightly. Here we override the resolver to generate cache files through the resolver  which points to S3 bucket: Conclusions VichUploaderBundle, LiipImagineBundle and Gaufrette are three great Symfony2 bundles. The configuration to make work all them can by tricky so hope this post can help others. While VichUploaderBundle is designed to work with Gaufrette, and its configuration is almost trivial, LiipImagineBundle is not and requires some extra tasks. For LiipImagineBundle we need to configure its main components, which are the cache and the ."}}]}},"pageContext":{"isCreatedByStatefulCreatePages":false,"limit":6,"skip":6,"numPages":18,"currentPage":2}}}